{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 这里是 Markdown 单元格\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World, Hello PyTorch 2.5.1\n",
      "\n",
      "CUDA is available:False, version is None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(\"Hello World, Hello PyTorch {}\".format(torch.__version__))\n",
    "\n",
    "print(\"\\nCUDA is available:{}, version is {}\".format(\n",
    "    torch.cuda.is_available(), torch.version.cuda))\n",
    "\n",
    "# print(\"\\ndevice_name: {}\".format(torch.cuda.get_device_name(0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1\n",
      "CUDA Version: None\n",
      "Is CUDA Available: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "print(f\"Is CUDA Available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(\n",
    "            f\"  Memory Allocated: {torch.cuda.memory_allocated(i) / (1024 ** 2):.2f} MB\")\n",
    "        print(\n",
    "            f\"  Memory Cached: {torch.cuda.memory_reserved(i) / (1024 ** 2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 两个神奇操作\n",
    "\n",
    "! 以及 %% 使用\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Mar 07 16:40:43 2025       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 457.56       Driver Version: 457.56       CUDA Version: 11.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  GeForce MX350      WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   48C    P8    N/A /  N/A |     68MiB /  2048MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     16012    C+G   D:\\Tencent\\QQNT\\QQ.exe          N/A      |\n",
      "+-----------------------------------------------------------------------------+\n",
      "Active code page: 65001\n",
      "中文\n",
      "16:40\n",
      " Volume in drive D is Data\n",
      " Volume Serial Number is E667-FC32\n",
      "\n",
      " Directory of d:\\ai\\pytorch\\l-PyTorch-Tutorial-2nd\\code\\chapter-1\n",
      "\n",
      "2025/02/21  17:05    <DIR>          .\n",
      "2025/02/21  17:05    <DIR>          ..\n",
      "2025/03/07  16:32               525 01-hello-pytorch.py\n",
      "2025/03/07  16:27             6,053 02-notebook-demo.ipynb\n",
      "2024/12/13  17:24             6,220 03-torch-compile-performance.py\n",
      "2024/12/13  17:24            11,748 03-torch-compile.ipynb\n",
      "               4 File(s)         24,546 bytes\n",
      "               2 Dir(s)  35,629,158,400 bytes free\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!chcp 65001\n",
    "!echo 中文\n",
    "!time /t\n",
    "!dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584 ns ± 35.8 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "a = []\n",
    "for i in range(10):\n",
    "    a.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 127 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a = []\n",
    "for i in range(1000000):\n",
    "    a.append(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "v3.11.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
