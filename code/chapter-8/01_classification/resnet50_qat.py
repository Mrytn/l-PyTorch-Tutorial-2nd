# -*- coding:utf-8 -*-
"""
@file name  : resnet50_qat.py
@author     : TingsongYu https://github.com/TingsongYu
@date       : 2023-02-04
@brief      : è‚ºç‚Xrayå›¾åƒåˆ†ç±»æ¨¡å‹ï¼Œresnet50 QAT é‡åŒ–
"""
from datasets.pneumonia_dataset import PneumoniaDataset
import utils.my_utils as utils
import os
import time
import datetime
import torchvision
import torch
import torch.nn as nn
import matplotlib
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.tensorboard import SummaryWriter
from torch.utils.data import DataLoader

from pytorch_quantization import nn as quant_nn
from pytorch_quantization import quant_modules

matplotlib.use('Agg')


def get_args_parser(add_help=True):
    import argparse

    parser = argparse.ArgumentParser(
        description="PyTorch Classification Training", add_help=add_help)

    parser.add_argument(
        "--data-path", default=r"G:\deep_learning_data\chest_xray", type=str, help="dataset path")
    parser.add_argument(
        "--ckpt-path", default=r"./Result/2023-09-26_01-47-40/checkpoint_best.pth", type=str, help="ckpt path")
    parser.add_argument("--model", default="resnet50", type=str,
                        help="model name; resnet50/convnext/convnext-tiny")
    parser.add_argument("--device", default="cuda", type=str,
                        help="device (Use cuda or cpu Default: cuda)")
    parser.add_argument(
        "-b", "--batch-size", default=8, type=int, help="images per gpu, the total batch size is $NGPU x batch_size"
    )
    parser.add_argument("--epochs", default=5, type=int,
                        metavar="N", help="number of total epochs to run")
    # DataLoader è¯»å–æ•°æ®çš„çº¿ç¨‹æ•°
    parser.add_argument(
        "-j", "--workers", default=4, type=int, metavar="N", help="number of data loading workers (default: 4)")
    # ä¼˜åŒ–å™¨
    parser.add_argument("--opt", default="sgd", type=str, help="optimizer")
    # è®¾ç½®éšæœºç§å­ï¼Œä¿è¯ç»“æœå¯å¤ç°
    parser.add_argument("--random-seed", default=42,
                        type=int, help="random seed")
    parser.add_argument("--lr", default=0.01/100,
                        type=float, help="initial learning rate")
    # SGD åŠ¨é‡å‚æ•°
    parser.add_argument("--momentum", default=0.9,
                        type=float, metavar="M", help="momentum")
    # æƒé‡è¡°å‡ç³»æ•°ï¼ˆL2æ­£åˆ™åŒ–ï¼‰
    parser.add_argument(
        "--wd",
        "--weight-decay",
        default=1e-4,
        type=float,
        metavar="W",
        help="weight decay (default: 1e-4)",
        dest="weight_decay",)
    # æ—¥å¿—æ‰“å°é¢‘ç‡ï¼ˆæ¯å‡ è½® epoch æ‰“å°ä¸€æ¬¡ï¼‰
    parser.add_argument("--print-freq", default=20,
                        type=int, help="print frequency")
    parser.add_argument("--output-dir", default="./Result",
                        type=str, help="path to save outputs")
    # æŒ‡å®šè®­ç»ƒä»ç¬¬å‡ è½®å¼€å§‹ï¼ˆç”¨äºæ–­ç‚¹æ¢å¤ï¼‰
    parser.add_argument("--start-epoch", default=0, type=int,
                        metavar="N", help="start epoch")

    return parser


def main(args):
    device = args.device
    data_dir = args.data_path
    result_dir = args.output_dir
    # ------------------------------------  log ------------------------------------
    logger, log_dir = utils.make_logger(result_dir)
    writer = SummaryWriter(log_dir=log_dir)
    # ------------------------------------ step1: dataset ------------------------------------

    normMean = [0.5]
    normStd = [0.5]
    input_size = (224, 224)
    normTransform = transforms.Normalize(normMean, normStd)
    train_transform = transforms.Compose([
        transforms.Resize(256),
        transforms.RandomCrop(input_size, padding=4),
        transforms.ToTensor(),
        normTransform
    ])

    valid_transform = transforms.Compose([
        transforms.Resize(input_size),
        transforms.ToTensor(),
        normTransform
    ])

    # chest_xray.zip è§£å‹ï¼Œè·å¾— chest_xray/train, chest_xray/test
    # æ•°æ®å¯ä» https://data.mendeley.com/datasets/rscbjbr9sj/2 ä¸‹è½½
    train_dir = os.path.join(data_dir, 'train')
    valid_dir = os.path.join(data_dir, 'test')
    train_set = PneumoniaDataset(train_dir, transform=train_transform)
    valid_set = PneumoniaDataset(valid_dir, transform=valid_transform)

    # æ„å»ºDataLoder
    train_loader = DataLoader(
        dataset=train_set, batch_size=args.batch_size, shuffle=True, num_workers=args.workers)
    valid_loader = DataLoader(
        dataset=valid_set, batch_size=8, num_workers=args.workers)

    # ------------------------------------ tep2: model ------------------------------------
    if args.model == 'resnet50':
        model = torchvision.models.resnet50(pretrained=True)
    elif args.model == 'convnext':
        model = torchvision.models.convnext_base(pretrained=True)
    elif args.model == 'convnext-tiny':
        model = torchvision.models.convnext_tiny(pretrained=True)
    else:
        logger.error('unexpect model --> :{}'.format(args.model))

    model_name = model._get_name()

    if 'ResNet' in model_name:
        # æ›¿æ¢ç¬¬ä¸€å±‚ï¼š å› ä¸ºé¢„è®­ç»ƒæ¨¡å‹è¾“å…¥æ˜¯3é€šé“ï¼Œè€Œæœ¬æ¡ˆä¾‹æ˜¯ç°åº¦å›¾ï¼Œè¾“å…¥æ˜¯1é€šé“
        model.conv1 = nn.Conv2d(1, 64, (7, 7), stride=(
            2, 2), padding=(3, 3), bias=False)
        num_ftrs = model.fc.in_features  # æ›¿æ¢æœ€åä¸€å±‚
        model.fc = nn.Linear(num_ftrs, 2)
    elif 'ConvNeXt' in model_name:
        # æ›¿æ¢ç¬¬ä¸€å±‚ï¼š å› ä¸ºé¢„è®­ç»ƒæ¨¡å‹è¾“å…¥æ˜¯3é€šé“ï¼Œè€Œæœ¬æ¡ˆä¾‹æ˜¯ç°åº¦å›¾ï¼Œè¾“å…¥æ˜¯1é€šé“
        num_kernel = 128 if args.model == 'convnext' else 96
        model.features[0][0] = nn.Conv2d(
            1, num_kernel, (4, 4), stride=(4, 4))  # convnext base/ tiny
        # æ›¿æ¢æœ€åä¸€å±‚
        num_ftrs = model.classifier[2].in_features
        model.classifier[2] = nn.Linear(num_ftrs, 2)

    # ------------------------- åŠ è½½è®­ç»ƒæƒé‡
    state_dict = torch.load(args.ckpt_path)
    model_sate_dict = state_dict['model_state_dict']
    model.load_state_dict(model_sate_dict)  # æ¨¡å‹å‚æ•°åŠ è½½

    model.to(device)

    # ------------------------------------ step3: optimizer, lr scheduler ------------------------------------
    criterion = nn.CrossEntropyLoss()  # é€‰æ‹©æŸå¤±å‡½æ•°
    # ä½¿ç”¨ éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰+ åŠ¨é‡é¡¹ï¼ˆmomentumï¼‰+ æƒé‡è¡°å‡ï¼ˆL2æ­£åˆ™åŒ–ï¼‰ æ¥ä¼˜åŒ–æ¨¡å‹å‚æ•°ã€‚
    optimizer = optim.SGD(model.parameters(), lr=args.lr, momentum=args.momentum,
                          weight_decay=args.weight_decay)  # é€‰æ‹©ä¼˜åŒ–å™¨
    # ç”¨ ä½™å¼¦é€€ç«ï¼ˆCosine Annealingï¼‰ç­–ç•¥åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡ï¼Œåœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€æ¸é™ä½ã€‚
    # T_max æ˜¯æ€»è½®æ•°ï¼ˆå‘¨æœŸé•¿åº¦ï¼‰ï¼Œeta_min æ˜¯æœ€å°å­¦ä¹ ç‡ã€‚
    # å­¦ä¹ ç‡åƒä½™å¼¦æ›²çº¿ä¸€æ ·ä»é«˜åˆ°ä½å¹³æ»‘ä¸‹é™ï¼Œè¿™æ ·å‰æœŸå¿«é€Ÿå­¦ä¹ ã€åæœŸç²¾ç»†è°ƒæ•´ï¼Œæé«˜æ”¶æ•›è´¨é‡ã€‚
    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=args.epochs, eta_min=args.lr/100)  # è®¾ç½®å­¦ä¹ ç‡ä¸‹é™ç­–ç•¥

    # ------------------------------------ step4: iteration ------------------------------------
    logger.info(args)
    logger.info("Start training")
    for epoch in range(args.start_epoch, args.epochs):
        # è®­ç»ƒ
        loss_m_train, acc_m_train, mat_train = \
            utils.ModelTrainer.train_one_epoch(train_loader, model, criterion, optimizer, scheduler,
                                               epoch, device, args, logger, classes)
        # éªŒè¯
        loss_m_valid, acc_m_valid, mat_valid = \
            utils.ModelTrainer.evaluate(
                valid_loader, model, criterion, device, classes)
        # è·å–å½“å‰å­¦ä¹ ç‡ï¼ˆä»¥åˆ—è¡¨å½¢å¼è¿”å›ï¼Œå–ç¬¬ä¸€ä¸ªï¼‰
        # æœ‰å‡ ä¸ªå‚æ•°ç»„å°±æœ‰å‡ ä¸ªå­¦ä¹ ç‡ï¼Œè¿™é‡Œåªå–ç¬¬ä¸€ä¸ªå‚æ•°ç»„çš„å­¦ä¹ ç‡
        lr_current = scheduler.get_last_lr()[0]
        logger.info(
            'Epoch: [{:0>3}/{:0>3}]  '
            'Train Loss avg: {loss_train.avg:>6.4f}  '
            'Valid Loss avg: {loss_valid.avg:>6.4f}  '
            'Train Acc@1 avg:  {top1_train.avg:>7.4f}   '
            'Valid Acc@1 avg: {top1_valid.avg:>7.4f}    '
            'LR: {lr}'.format(
                epoch, args.epochs, loss_train=loss_m_train, loss_valid=loss_m_valid,
                top1_train=acc_m_train, top1_valid=acc_m_valid, lr=lr_current))

        # å­¦ä¹ ç‡è°ƒç”¨
        # æ¯è°ƒç”¨ step() æ»¡ step_size æ¬¡æ›´æ–°
        scheduler.step()
        # è®°å½•
        conf_mat_figure_train = utils.show_conf_mat(mat_train, classes, "train", log_dir, epoch=epoch,
                                                    verbose=epoch == args.epochs - 1, save=True)
        conf_mat_figure_valid = utils.show_conf_mat(mat_valid, classes, "valid", log_dir, epoch=epoch,
                                                    verbose=epoch == args.epochs - 1, save=True)
        writer.add_figure('confusion_matrix_train',
                          conf_mat_figure_train, global_step=epoch)
        writer.add_figure('confusion_matrix_valid',
                          conf_mat_figure_valid, global_step=epoch)
        writer.add_scalar('learning rate', lr_current, epoch)

    # ------------------------------------ è®­ç»ƒå®Œæ¯•æ¨¡å‹ä¿å­˜ ------------------------------------
    # è¿™æ®µä»£ç çš„ç›®çš„æ˜¯å°† QATï¼ˆQuantization-Aware Trainingï¼‰åçš„æ¨¡å‹å¯¼å‡ºä¸º ONNX æ ¼å¼ï¼Œä»¥ä¾¿è¿›è¡Œæ¨ç†éƒ¨ç½²
    # Fake Quantization æ˜¯ä¸€ç§æ¨¡æ‹Ÿé‡åŒ–çš„æ–¹å¼ï¼Œå®ƒåœ¨è®­ç»ƒæ—¶æ¨¡æ‹Ÿé‡åŒ–è¯¯å·®ï¼Œä½†æƒé‡ä»ç„¶æ˜¯ float32ã€‚
# è®¾ç½®è¿™ä¸ªå€¼å¯ä»¥ç¡®ä¿å¯¼å‡º ONNX æ—¶ä½¿ç”¨ fake quant ç®—å­ï¼Œè€Œä¸æ˜¯çœŸå®çš„ int8 å€¼ã€‚
    quant_nn.TensorQuantizer.use_fb_fake_quant = True
    for bs in [1, 32]:
        model_name = "resnet_50_qat_bs{}_{:.2%}.onnx".format(
            bs, acc_m_valid.avg / 100)
        onnx_path = os.path.join(log_dir, model_name)
        dummy_input = torch.randn(bs, 1, 224, 224, device='cuda')
        # do_constant_folding=Falseï¼šæ˜¯å¦åœ¨å¯¼å‡ºæ—¶è¿›è¡Œå¸¸é‡æŠ˜å ä¼˜åŒ–ï¼ˆæ­¤å¤„å…³é—­ï¼Œå¯èƒ½æ˜¯ä¸ºäº†ä¿æŒ fake quant opsï¼‰
        torch.onnx.export(model, dummy_input, onnx_path, opset_version=13, do_constant_folding=False,
                          input_names=['input'], output_names=['output'])


classes = ["NORMAL", "PNEUMONIA"]


if __name__ == "__main__":
    #     quant_modules ä¸€èˆ¬æ¥è‡ª from pytorch_quantization import quant_modules
    # è¿™è¡Œä»£ç ä¼šå°† PyTorch ä¸­çš„éƒ¨åˆ†æ ‡å‡†å±‚ï¼ˆå¦‚ nn.Conv2d, nn.Linear, nn.ReLU ç­‰ï¼‰æ›¿æ¢ä¸ºå®ƒä»¬çš„å¯é‡åŒ–ç‰ˆæœ¬ï¼Œå¦‚ QuantConv2dã€QuantLinearã€‚
    # æ›¿æ¢åï¼Œä½ åŸå§‹çš„æ¨¡å‹ç»“æ„å¯ä»¥ç›´æ¥åŠ å…¥é‡åŒ–èŠ‚ç‚¹è€Œæ— éœ€æ‰‹åŠ¨æ›¿æ¢æ¯ä¸ªå­æ¨¡å—ã€‚
    # ğŸ“Œ ç›®çš„ï¼šä¸º QATï¼ˆQuantization-Aware Trainingï¼‰åšå¥½æ¨¡å‹ç»“æ„çš„å‡†å¤‡ã€‚
    # åªå½±å“ åç»­æ„å»º çš„æ¨¡å‹ï¼›å·²æ„å»ºæ¨¡å‹ä¸å—å½±å“
    # æ¢å¤ï¼Œåªéœ€è°ƒç”¨ quant_modules.deactivate()ã€‚
    quant_modules.initialize()  # æ›¿æ¢torch.nnçš„å¸¸ç”¨å±‚ï¼Œå˜ä¸ºå¯é‡åŒ–çš„å±‚

    args = get_args_parser().parse_args()
    utils.setup_seed(args.random_seed)
    args.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    main(args)
