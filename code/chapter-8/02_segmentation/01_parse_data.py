# -*- coding:utf-8 -*-
"""
@file name  : 01_parse_data.py
@author     : TingsongYu https://github.com/TingsongYu
@date       : 2023-03-04
@brief      : è§£ææ•°æ®ï¼Œä¿å­˜ä¸ºdataframeå½¢å¼ï¼Œå¹¶åˆ’åˆ†æ•°æ®é›†
@reference  : https://www.kaggle.com/code/truthisneverlinear/tumor-segmentation-91-accuracy-pytorch
"""
import os
import pandas as pd
import numpy as np
import cv2
import argparse
import matplotlib.pyplot as plt
from mpl_toolkits.axes_grid import ImageGrid
from sklearn.model_selection import train_test_split


def cv_imread(path_file):
    cv_img = cv2.imdecode(np.fromfile(
        path_file, dtype=np.uint8), cv2.IMREAD_UNCHANGED)
    # è¿”å›å€¼ numpy.ndarray
    return cv_img


def data_parse():
    """
    æ ¹æ®ç›®å½•ç»“æ„ï¼Œè¯»å–å›¾ç‰‡ã€æ ‡ç­¾çš„è·¯å¾„åŠæ‚£è€…id
    :return:
    """
    data = []

    # è·å–å›¾ç‰‡ä¿¡æ¯ï¼Œå­˜å‚¨äºdataframe
    for dir_ in os.listdir(data_dir):
        dir_path = os.path.join(data_dir, dir_)
        if os.path.isdir(dir_path):
            for filename in os.listdir(dir_path):
                img_path = os.path.join(dir_path, filename)
                data.append([dir_, img_path])
        else:
            print(f'This is not a dir --> {dir_path}')

    # åˆ†åˆ«è·å–å›¾ç‰‡ä¸æ ‡ç­¾çš„è·¯å¾„ä¿¡æ¯
    df = pd.DataFrame(data, columns=["patient", "image_path"])
    # è¿‡æ»¤å‡ºéæ©ç å›¾åƒçš„è·¯å¾„
# str.contains("mask")ï¼šè¿”å›å¸ƒå°”å€¼ï¼Œè¡¨ç¤ºæ¯ä¸ªè·¯å¾„ä¸­æ˜¯å¦åŒ…å« "mask"
# ~ æ˜¯å–åæ“ä½œï¼Œè¡¨ç¤ºâ€œä¸æ˜¯æ©ç â€çš„è·¯å¾„
    df_imgs = df[~df["image_path"].str.contains("mask")]
    # x[:-4]æ˜¯æˆªå–ç¬¬ä¸€ä¸ªåˆ°å€’æ•°ç¬¬5ä¸ª
    # å‡è®¾åŸå›¾æ˜¯ "001_image.tif"ï¼Œåˆ™æ©ç è·¯å¾„æ˜¯ "001_image_mask.tif"
# ğŸ” x[:-4] + "_mask.tif" è§£é‡Šï¼š
# x[:-4]ï¼šå»æ‰ .tif æ‰©å±•åï¼ˆå› ä¸º .tif æ˜¯ 4 ä¸ªå­—ç¬¦ï¼‰
# ç„¶åæ‹¼æ¥ä¸Š _mask.tifï¼Œå½¢æˆå®Œæ•´æ©ç è·¯å¾„
    df_imgs["mask_path"] = df_imgs["image_path"].apply(
        lambda x: x[:-4] + "_mask.tif")

    # æœ€ç»ˆdfï¼ŒåŒ…å«æ‚£è€…idï¼Œå›¾ç‰‡è·¯å¾„ï¼Œæ ‡ç­¾è·¯å¾„
    dff = df_imgs

    # æ–°å¢ä¸€åˆ—åˆ¤æ–­æ˜¯å¦æœ‰è‚¿ç˜¤
    # æ ¹æ®æ©ç å›¾åƒæ˜¯å¦æœ‰â€œå‰æ™¯åƒç´ â€æ¥åˆ¤æ–­è¯¥å›¾åƒæ˜¯å¦ä¸ºâ€œé˜³æ€§â€æˆ–â€œé˜´æ€§â€è¯Šæ–­ç»“æœï¼Œç„¶åæŠŠè¿™ä¸ªè¯Šæ–­ç»“æœæ·»åŠ åˆ° DataFrame ä¸­ï¼Œå¹¶ä¿å­˜æˆ CSV æ–‡ä»¶
    def pos_neg_diagnosis(mask_path):
        # np.max(...)ï¼šæŸ¥çœ‹å›¾åƒä¸­æ˜¯å¦æœ‰é 0 åƒç´ 
        return_value = 1 if np.max(cv_imread(mask_path)) > 0 else 0
        return return_value
    dff["diagnosis"] = dff["mask_path"].apply(lambda x: pos_neg_diagnosis(x))
    # å°†åŒ…å« patient, image_path, mask_path, diagnosis çš„ DataFrame ä¿å­˜æˆ CSV æ–‡ä»¶ã€‚
# index=False è¡¨ç¤ºä¸è¦ä¿å­˜è¡Œå·ç´¢å¼•åˆ—
    dff.to_csv(PATH_SAVE, index=False)


def data_analysis():
    """
    æ ¹æ®csvæ–‡ä»¶ï¼Œåˆ†ææ­£è´Ÿå›¾ç‰‡æ¯”ä¾‹ï¼Œåˆ†ææ¯ä¸ªæ‚£è€…çš„æ­£è´Ÿå›¾ç‰‡æ¯”ä¾‹
    :return:
    """

    dff = pd.read_csv(PATH_SAVE)
    # å¯¹ diagnosis åˆ—ä¸­ä¸åŒçš„å€¼ï¼ˆä¾‹å¦‚ Positive/Negativeï¼‰è¿›è¡Œè®¡æ•°ï¼Œè¿”å›ä¸€ä¸ªæŒ‰é¢‘æ•°é™åºæ’åˆ—çš„ Series
    # color=["violet", "orange"]ï¼šè®¾ç½®æŸ±å­çš„é¢œè‰²åˆ—è¡¨ï¼ŒæŒ‰åˆ†ç±»é¡ºåºåº”ç”¨é¢œè‰²ã€‚stacked=True çš„ä½œç”¨æ˜¯ï¼šåœ¨æŸ±çŠ¶å›¾æˆ–æŠ˜çº¿å›¾ä¸­ï¼Œå°†åŒä¸€ä¸ª x è½´æ ‡ç­¾ä¸‹çš„å¤šä¸ªæ•°å€¼â€œå †å â€åœ¨ä¸€èµ·ç»˜åˆ¶ï¼Œè€Œä¸æ˜¯åˆ†åˆ«å¹¶æ’æ˜¾ç¤º
    ax = dff.diagnosis.value_counts().plot(kind="bar", stacked=True,
                                           figsize=(10, 6), color=["violet", "orange"])
    # è®¾ç½®åæ ‡è½´ & æ ‡é¢˜ï¼š
    ax.set_xticklabels(["Positive", "Negative"], rotation=45, fontsize=12)
    # åº”è¯¥æ”¹ä¸ºåˆ—è¡¨
    ax.set_yticklabels("Total Images", fontsize=12)
    ax.set_title("Distribution of Data Grouped by Diagnosis",
                 fontsize=18, y=1.05)
    # ç»™æ¯ä¸ªæŸ±å­æ·»åŠ æ ‡ç­¾
    # è¿™æ®µä»£ç åœ¨ä½ ç”»å®ŒæŸ±çŠ¶å›¾åï¼š
# å¯¹æ¯ä¸ªæŸ±å­éƒ½æ·»åŠ äº†ç™½è‰²çš„æ•°å­—æ ‡æ³¨ï¼›
# ä½ç½®æ˜¯â€œæŸ±å­å†…éƒ¨æ¥è¿‘é¡¶éƒ¨â€ï¼›
# å­—ä½“å¤§è€Œé†’ç›®ï¼Œé€‚åˆå±•ç¤ºåˆ†ç±»ç»Ÿè®¡å›¾
    for i, rows in enumerate(dff.diagnosis.value_counts().values):
        ax.annotate(
            int(rows),                  # æ ‡æ³¨çš„æ–‡å­—å†…å®¹ï¼ˆå³è®¡æ•°å€¼ï¼‰
            xy=(i, rows - 12),          # æ ‡æ³¨çš„ä½ç½®ï¼Œx ä¸ºæŸ±å­çš„ç´¢å¼•ï¼Œy ä¸ºæŸ±å­çš„é«˜åº¦å‡å» 12
            rotation=0,                 # æ°´å¹³æ–‡å­—ï¼ˆä¸æ—‹è½¬ï¼‰
            color="white",              # æ–‡å­—é¢œè‰²ä¸ºç™½è‰²
            ha="center",                # æ°´å¹³å±…ä¸­
            verticalalignment='bottom',  # å‚ç›´åº•å¯¹é½ï¼ˆä»æŒ‡å®šç‚¹å‘ä¸Šå»¶ä¼¸ï¼‰
            fontsize=15,                # å­—å·
            fontweight="bold"          # åŠ ç²—
        )

    # åœ¨åæ ‡ (x=1.2, y=2550) çš„ä½ç½®æ·»åŠ ä¸€æ®µæ–‡æœ¬ï¼ˆå›¾è¡¨åæ ‡ç³»ä¸‹çš„ä½ç½®ï¼‰ã€‚

    # æ–‡æœ¬å†…å®¹ä¸ºï¼šä¾‹å¦‚ "Total 1000 images"ã€‚
    # bbox=...ï¼šæ·»åŠ äº†ä¸€ä¸ªå¸¦åœ†è§’çš„è“è‰²èƒŒæ™¯æ¡†ï¼ˆç”¨äºçªå‡ºæ˜¾ç¤ºæ–‡æœ¬ï¼‰ã€‚
    # boxstyle="round"
# è®¾ç½®æ–‡æœ¬æ¡†çš„å½¢çŠ¶ï¼ˆæ ·å¼ï¼‰ã€‚
# fc æ˜¯ facecolor çš„ç®€å†™ï¼Œè¡¨ç¤ºå¡«å……é¢œè‰²ã€‚
# ä½ è¿™é‡Œè®¾ç½®ä¸º "lightblue"ï¼Œå³æµ…è“è‰²ï¼Œç”¨äºä½œä¸ºæ–‡å­—æ¡†çš„èƒŒæ™¯ã€‚fc æ˜¯ facecolor çš„ç®€å†™ï¼Œè¡¨ç¤ºå¡«å……é¢œè‰²ã€‚
# ä½ è¿™é‡Œè®¾ç½®ä¸º "lightblue"ï¼Œå³æµ…è“è‰²ï¼Œç”¨äºä½œä¸ºæ–‡å­—æ¡†çš„èƒŒæ™¯ã€‚
# "round" è¡¨ç¤ºï¼šåœ†è§’çŸ©å½¢ï¼Œç›¸æ¯”æ™®é€šçŸ©å½¢æ›´åŠ æŸ”å’Œ
    ax.text(1.2, 2550, f"Total {len(dff)} images", size=15, color="black", ha="center", va="center",
            bbox=dict(boxstyle="round", fc=("lightblue")))
    # è®¾ç½®æ•´ä¸ªå›¾è¡¨çš„èƒŒæ™¯è‰²ä¸ºæ·±ç°è‰²ï¼ˆRGB å½¢å¼ï¼Œå€¼åœ¨ 0~1 èŒƒå›´ï¼Œ0.15 â‰ˆ 38/255ï¼‰
    ax.set_facecolor((0.15, 0.15, 0.15))
    plt.show()
    # --------------------------------------- è§‚å¯Ÿæ­£è´Ÿå›¾ç‰‡æ•°é‡æ¯”ä¾‹ ------------------------------------------------------------
    patients_by_diagnosis = dff.groupby(["patient", "diagnosis"])[
        "diagnosis"].size().unstack().fillna(0)
    # æ›´ä¿é™©çš„å†™æ³•åº”è¯¥æ ¹æ® diagnosis åŸå§‹å€¼åˆ¤æ–­é¡ºåº
    # patients_by_diagnosis.columns = ['Positive' if col == 1 else 'Negative' for col in patients_by_diagnosis.columns]
    patients_by_diagnosis.columns = ["Positive", "Negative"]
    # æ¯ä¸€ä¸ªæŸ±å­è¡¨ç¤ºä¸€ä¸ªæ‚£è€…ï¼›
# æŸ±å­ä¸­å †å ä¸¤ç§é¢œè‰²ï¼šé˜³æ€§å›¾åƒå’Œé˜´æ€§å›¾åƒçš„æ•°é‡ï¼›
    ax = patients_by_diagnosis.plot(kind="bar", stacked=True, figsize=(18, 10), color=["violet", "springgreen"],
                                    alpha=0.85)
    ax.legend(fontsize=20, loc="upper left")
    ax.grid(False)
    ax.set_xlabel('Patients', fontsize=20)
    ax.set_ylabel('Total Images', fontsize=20)
    ax.set_title(
        "Distribution of data grouped by patient and diagnosis", fontsize=25, y=1.005)
    plt.show()


def data_visual():
    """
    å°†å›¾ç‰‡ã€æ ‡ç­¾è¯»å–å¹¶å¯è§†åŒ–
    :return:
    """
    dff = pd.read_csv(PATH_SAVE)

    # masks
    # è¯»å–æ•°æ®å¹¶æŠ½æ ·
    sample_df = dff[dff["diagnosis"] == 1].sample(5).values

    sample_imgs = []
    # é€ä¸ªè¯»å–å›¾åƒä¸æ©ç ï¼Œå¹¶ç¼©æ”¾åˆ°ä¸€è‡´å¤§å°
# ç”¨ .extend() æŠŠå›¾åƒä¸æ©ç ä¾æ¬¡æ·»åŠ åˆ° sample_imgs åˆ—è¡¨ä¸­
    for i, data in enumerate(sample_df):
        img = cv2.resize(cv_imread(data[1]), (IMG_SHOW_SIZE, IMG_SHOW_SIZE))
        mask = cv2.resize(cv_imread(data[2]), (IMG_SHOW_SIZE, IMG_SHOW_SIZE))
        # æŒ‰é¡ºåºæ·»åŠ img, maskï¼Œåˆ†åˆ«ä¸ºç´¢å¼•0,1
        sample_imgs.extend([img, mask])
    # æå–å¶æ•°ç´¢å¼•ï¼Œå³åŸå›¾
    sample_img_arr = np.hstack(sample_imgs[::2])
    # æå–å¥‡æ•°ç´¢å¼•ï¼Œå³æ©ç 
    sample_mask_arr = np.hstack(sample_imgs[1::2])

    # Plot
    fig = plt.figure(figsize=(25., 25.))
    # axes_pad=0.1ï¼šè¡¨ç¤ºå­å›¾ä¹‹é—´çš„é—´è·ä¸º 0.1 è‹±å¯¸ï¼Œæ§åˆ¶å›¾åƒä¹‹é—´çš„ç©ºç™½ã€‚
    # 111	ç»§æ‰¿è‡ª subplot çš„è¯­æ³•ï¼Œè¡¨ç¤ºå ç”¨æ•´ä¸ªç”»å¸ƒåŒºåŸŸ
    grid = ImageGrid(fig, 111,  # similar to subplot(111)
                     nrows_ncols=(2, 1),  # creates 2x2 grid of axes
                     axes_pad=0.1,  # pad between axes in inch.
                     )

    grid[0].imshow(sample_img_arr)
    grid[0].set_title("Images", fontsize=25)
    grid[0].axis("off")
    grid[0].grid(False)

    grid[1].imshow(sample_mask_arr)
    grid[1].set_title("Masks", fontsize=25, y=0.9)
    grid[1].axis("off")
    grid[1].grid(False)

    plt.show()


def data_split():
    """
    å°†æ•°æ®åˆ’åˆ†ä¸ºè®­ç»ƒé›†ã€éªŒè¯é›†ï¼Œè¿™é‡Œä»¥dataframeå½¢å¼å­˜å‚¨
    :return:
    """
    dff = pd.read_csv(PATH_SAVE)

    # éœ€è¦æ ¹æ®æ‚£è€…ç»´åº¦åˆ’åˆ†ï¼Œä¸å¯é€šè¿‡å›¾ç‰‡ç»´åº¦åˆ’åˆ†ï¼Œä»¥ä¸‹ä»£ç å¯ç”¨äºå¸¸è§çš„csvåˆ’åˆ†
    grouped = dff.groupby('patient')
    # grouped = dff.groupby('image_path')  # bad method
    # åˆ’åˆ†è®­ç»ƒ/éªŒè¯é›†
    train_set, val_set = train_test_split(
        list(grouped), train_size=train_size, random_state=42)
    # ii[1] æ˜¯æ¯ç»„å¯¹åº”çš„ DataFrameï¼ˆå›¾åƒè®°å½•ï¼‰
# è¿™ä¸€æ­¥æŠŠæ¯ä¸ªæ‚£è€…çš„æ•°æ®æå–å‡ºæ¥æ”¾å…¥åˆ—è¡¨ä¸­ã€‚
    train_set, val_set = [ii[1] for ii in train_set], [ii[1] for ii in val_set]  # æå–dataframe
    train_df, val_df = pd.concat(train_set), pd.concat(val_set)  # åˆå¹¶dataframe

    train_df.to_csv(PATH_SAVE_TRAIN, index=False)
    val_df.to_csv(PATH_SAVE_VAL, index=False)
    print(f"Train: {train_df.shape} \nVal: {val_df.shape}")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(add_help=True)
    parser.add_argument("--data-path", default=r"G:\deep_learning_data\brain-seg\kaggle_3m",
                        type=str, help="dataset path")
    # å°†å‘½ä»¤è¡Œè¾“å…¥çš„å‚æ•°è§£æä¸º args å¯¹è±¡
    args = parser.parse_args()

    data_dir = args.data_path  # xxx/kaggle_3m
    PATH_SAVE = 'data_info.csv'
    # PATH_SAVE_TRAIN = 'data_train_split_by_img.csv'
    # PATH_SAVE_VAL = 'data_val_split_by_img.csv'
    PATH_SAVE_TRAIN = 'data_train.csv'
    PATH_SAVE_VAL = 'data_val.csv'
    IMG_SHOW_SIZE = 512  # å¯è§†åŒ–æ—¶ï¼Œå›¾åƒå¤§å°
    train_size = 0.8  # è®­ç»ƒé›†åˆ’åˆ†æ¯”ä¾‹ï¼Œ80%

    data_parse()  # è¯»å–æ ¹ç›®å½•ä¸‹æ•°æ®ä¿¡æ¯ï¼Œå­˜å‚¨ä¸ºcsv
    data_analysis()  # åˆ†ææ•°æ®æ•°é‡ã€æ¯”ä¾‹
    data_visual()  # å¯è§†åŒ–åŸå›¾ä¸æ ‡ç­¾
    data_split()  # åˆ’åˆ†è®­ç»ƒé›†ã€éªŒè¯é›†
