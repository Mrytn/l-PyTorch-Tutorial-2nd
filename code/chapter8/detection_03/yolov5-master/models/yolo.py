# YOLOv5 ðŸš€ by Ultralytics, GPL-3.0 license
"""
YOLO-specific modules

Usage:
    $ python models/yolo.py --cfg yolov5s.yaml
"""
'''======================1.å¯¼å…¥å®‰è£…å¥½çš„pythonåº“====================='''
import contextlib
import argparse
from copy import deepcopy # æ•°æ®æ‹·è´æ¨¡å— æ·±æ‹·è´
from pathlib import Path
import platform
import sys
import os


'''===================2.èŽ·å–å½“å‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„========================'''
FILE = Path(__file__).resolve()
# parents[1] è¡¨ç¤º yolo.py æ–‡ä»¶çš„ ä¸Šä¸Šçº§ç›®å½•ï¼ˆå› ä¸º YOLOv5 é¡¹ç›®ä¸€èˆ¬æ˜¯ yolov5/models/yolo.pyï¼Œå¾€ä¸Šä¸¤å±‚å°±åˆ°äº† yolov5/ é¡¹ç›®æ ¹ç›®å½•ï¼‰
# è¦ç”¨é¡¹ç›®é‡Œçš„å…¶ä»–æ¨¡å—ä»£ç ï¼Œéƒ½å¿…é¡»è¦å…ˆæŠŠé¡¹ç›®æ ¹ç›®å½•åŠ åˆ°sys.path,ä¸”åœ¨å…¶ä»–æ¨¡å—å¯¼å…¥å‰åŠ 
ROOT = FILE.parents[1]  # YOLOv5 root directory
if str(ROOT) not in sys.path:
    sys.path.append(str(ROOT))  # add ROOT to PATH
if platform.system() != 'Windows':
    ROOT = Path(os.path.relpath(ROOT, Path.cwd()))  # relative
'''===================3..åŠ è½½è‡ªå®šä¹‰æ¨¡å—============================'''
# yolov5çš„ç½‘ç»œç»“æž„(yolov5)
from models.common import *
# å¯¼å…¥åœ¨çº¿ä¸‹è½½æ¨¡å—
from models.experimental import *
# å¯¼å…¥æ£€æŸ¥anchorsåˆæ³•æ€§çš„å‡½æ•°
from utils.autoanchor import check_anchor_order
# å®šä¹‰äº†ä¸€äº›å¸¸ç”¨çš„å·¥å…·å‡½æ•°
from utils.general import LOGGER, check_version, check_yaml, make_divisible, print_args
# å®šä¹‰äº†Annotatorç±»ï¼Œå¯ä»¥åœ¨å›¾åƒä¸Šç»˜åˆ¶çŸ©å½¢æ¡†å’Œæ ‡æ³¨ä¿¡æ¯
from utils.plots import feature_visualization
# å®šä¹‰äº†ä¸€äº›ä¸ŽPyTorchæœ‰å…³çš„å·¥å…·å‡½æ•°
from utils.torch_utils import (fuse_conv_and_bn, initialize_weights, model_info, profile, scale_img, select_device,time_sync)

try:
    # thop æ˜¯ä¸€ä¸ªç”¨äºŽ è®¡ç®—ç¥žç»ç½‘ç»œ FLOPsï¼ˆæµ®ç‚¹è¿ç®—æ¬¡æ•°ï¼‰å’Œå‚æ•°é‡ çš„åº“
    import thop  # for FLOPs computation
except ImportError:
    thop = None


class Detect(nn.Module):
    # YOLOv5 Detect head for detection models
    stride = None  # strides computed during build
    dynamic = False  # force grid reconstruction
    export = False  # export mode
    '''===================1.èŽ·å–é¢„æµ‹å¾—åˆ°çš„å‚æ•°============================'''
    def __init__(self, nc=80, anchors=(), ch=(), inplace=True):  # detection layer
        super().__init__()
        # æ•°æ®é›†ç±»åˆ«æ•°é‡
        self.nc = nc  # number of classes
        # è¡¨ç¤ºæ¯ä¸ªanchorçš„è¾“å‡ºæ•°ï¼Œå‰ncä¸ª01å­—ç¬¦å¯¹åº”ç±»åˆ«ï¼ŒåŽ5ä¸ªå¯¹åº”ï¼šæ˜¯å¦æœ‰ç›®æ ‡ï¼Œç›®æ ‡æ¡†çš„ä¸­å¿ƒï¼Œç›®æ ‡æ¡†çš„å®½é«˜
        self.no = nc + 5  # number of outputs per anchor
        # è¡¨ç¤ºé¢„æµ‹å±‚æ•°ï¼Œyolov5æ˜¯3å±‚é¢„æµ‹
        self.nl = len(anchors)  # number of detection layers
        # è¡¨ç¤ºanchorsçš„æ•°é‡ï¼Œé™¤ä»¥2æ˜¯å› ä¸º[10,13, 16,30, 33,23]è¿™ä¸ªé•¿åº¦æ˜¯6ï¼Œå¯¹åº”3ä¸ªancho
        self.na = len(anchors[0]) // 2  # number of anchors
        # æ¯ä¸ªæ£€æµ‹å±‚éƒ½éœ€è¦ä¸€ä¸ª gridï¼ˆç½‘æ ¼åæ ‡ï¼‰ æ¥è¾…åŠ©è§£ç é¢„æµ‹æ¡†ï¼ˆä»Žç‰¹å¾å›¾åæ ‡è¿˜åŽŸåˆ°è¾“å…¥å›¾åƒåæ ‡ï¼‰ã€‚
# self.nl è¡¨ç¤ºæœ‰å¤šå°‘ä¸ªæ£€æµ‹å±‚ï¼Œå°±åˆå§‹åŒ–å¤šå°‘ä¸ªç©ºçš„ gridã€‚
# åŽé¢åœ¨ forward æŽ¨ç†æ—¶ï¼Œä¼šæ ¹æ®å½“å‰ç‰¹å¾å›¾å¤§å°ç”Ÿæˆå¯¹åº”çš„ gridï¼ˆå¦‚æžœå’Œä¸Šä¸€æ¬¡çš„å¤§å°ä¸ä¸€è‡´ï¼‰ï¼Œè¿™æ ·æ¯ä¸ªæ£€æµ‹å±‚å°±æœ‰è‡ªå·±çš„ä¸€å¥—ç½‘æ ¼
# å­˜æ”¾ feature map çš„ç½‘æ ¼åæ ‡
        self.grid = [torch.empty(0) for _ in range(self.nl)]  # init grid
        # å­˜æ”¾ anchor å°ºå¯¸ï¼ˆåœ¨ forward æ—¶ reshapeï¼‰
        self.anchor_grid = [torch.empty(0) for _ in range(self.nl)]  # init anchor grid
        # æŠŠ anchors å­˜ä¸º bufferï¼Œä¸ä¼šè¢«ä¼˜åŒ–å™¨æ›´æ–°ï¼ˆä½†ä¼šéšæ¨¡åž‹ä¿å­˜/åŠ è½½ï¼‰ã€‚
# å½¢çŠ¶ (nl, na, 2)ï¼š
# nl = å±‚æ•°
# na = æ¯å±‚ anchor æ•°
# 2 = (w,h)
        self.register_buffer('anchors', torch.tensor(anchors).float().view(self.nl, -1, 2))  # shape(nl,na,2)
        # è¿™é‡Œçš„ 1 æ˜¯å·ç§¯æ ¸çš„å¤§å°ï¼Œä¹Ÿå°±æ˜¯ kernel_size=1ã€‚åªåšé€šé“æ•°æ˜ å°„ï¼Œä¸æ”¹å˜ç©ºé—´å°ºå¯¸
        # self.mï¼šæ¯ä¸ªæ£€æµ‹å±‚çš„å·ç§¯è¾“å‡ºå±‚ã€‚
# è¾“å…¥é€šé“ï¼šxï¼ˆç”± ch åˆ—è¡¨ç»™å®šï¼Œä¸åŒ feature map é€šé“æ•°å¯èƒ½ä¸åŒï¼‰ã€‚
# è¾“å‡ºé€šé“ï¼šno * naï¼Œå³æ¯ä¸ªåƒç´ ç‚¹é¢„æµ‹çš„ (nc+5) * anchorsã€‚
# kernel size = 1 â†’ pointwise å·ç§¯ï¼Œç›¸å½“äºŽé¢„æµ‹å¤´ã€‚
        self.m = nn.ModuleList(nn.Conv2d(x, self.no * self.na, 1) for x in ch)  # output conv
        # æ˜¯å¦åœ¨ forward ä¸­ä½¿ç”¨ inplace æ“ä½œï¼ŒèŠ‚çœå†…å­˜å¹¶æå‡é€Ÿåº¦ã€‚
        self.inplace = inplace  # use inplace ops (e.g. slice assignment)

    '''===================2.å‘å‰ä¼ æ’­============================'''
    # æŠŠ feature map è½¬æ¢æˆæœ€ç»ˆçš„é¢„æµ‹æ¡†
    # xæ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œå­˜æ”¾å„ä¸ªå°ºåº¦çš„ç‰¹å¾å›¾ [x_P3, x_P4, x_P5]
    def forward(self, x):
        # z ç”¨æ¥æ”¶é›†æ¯ä¸€å±‚ï¼ˆP3, P4, P5ï¼‰çš„é¢„æµ‹ç»“æžœï¼ˆåªåœ¨æŽ¨ç†æ—¶ç”¨ï¼‰
        z = []  # inference output
        # éåŽ†æ¯ä¸ªæ£€æµ‹å±‚
        for i in range(self.nl):
            # self.m æ¨¡å—åˆ—è¡¨ï¼Œå­˜æ”¾æ¯ä¸ªå°ºåº¦çš„è¾“å‡ºå·ç§¯ Conv2dï¼Œè¾“å‡ºé€šé“ = no * na
            # self.m[i](x[i])å¯¹ç¬¬ i ä¸ªå°ºåº¦çš„ç‰¹å¾å›¾åº”ç”¨å¯¹åº”å·ç§¯å±‚ï¼Œå¾—åˆ°é¢„æµ‹é€šé“
            # self.m é‡Œå°±å­˜äº† ä¸‰ä¸ªå·ç§¯å±‚P3 P4 P5
            x[i] = self.m[i](x[i])  # conv
            # x[i].shape = (batch_size, channels, height, width)
            # é€šé“æ•°ç­‰äºŽna*n0
            bs, _, ny, nx = x[i].shape  # x(bs,255,20,20) to x(bs,3,20,20,85)
            # æŠŠé€šé“ç»´æ‹†åˆ†æˆ anchor æ•° å’Œ æ¯ä¸ª anchor çš„é¢„æµ‹é€šé“æ•°ã€‚(batch_size, na, no, ny, nx)
            #batch_size = æ‰¹å¤§å°
# na = anchor æ•°
# no = æ¯ä¸ª anchor è¾“å‡ºæ•°ï¼ˆç±»åˆ«+åæ ‡+ç½®ä¿¡åº¦ï¼‰
# ny, nx = ç‰¹å¾å›¾é«˜å®½
# permute(0, 1, 3, 4, 2)æŠŠç»´åº¦é¡ºåºæ”¹æˆ æ–¹ä¾¿åŽç»­è§£ç 
# (batch_size, anchor, y, x, no)åŽŸæ¥æ˜¯ (batch, anchor, no, ny, nx)
            x[i] = x[i].view(bs, self.na, self.no, ny, nx).permute(0, 1, 3, 4, 2).contiguous()

            '''
            YOLOv5 Detect/Segment æŽ¨ç†é˜¶æ®µçš„æ ¸å¿ƒè§£ç é€»è¾‘ï¼Œä¸»è¦æ˜¯æŠŠå·ç§¯è¾“å‡ºè½¬æ¢æˆ çœŸå®žåæ ‡çš„é¢„æµ‹æ¡†
            '''
            if not self.training:  # inference
                # self.dynamic è¡¨ç¤ºæ˜¯å¦é‡‡ç”¨ åŠ¨æ€æŽ¨ç†æ¨¡å¼ã€‚
# å¦‚æžœä¸º Trueï¼Œåˆ™æ¯æ¬¡æŽ¨ç†éƒ½ä¼šé‡æ–°ç”Ÿæˆç½‘æ ¼ï¼ˆé€‚åˆè¾“å…¥å›¾åƒåˆ†è¾¨çŽ‡ç»å¸¸å˜åŒ–çš„æƒ…å†µï¼‰ã€‚
# å¦‚æžœä¸º Falseï¼Œåˆ™åªåœ¨æ£€æµ‹åˆ°ç‰¹å¾å›¾å°ºå¯¸æ”¹å˜æ—¶æ‰é‡æ–°ç”Ÿæˆä¸€æ¬¡ï¼ŒèŠ‚çœè®¡ç®—
# self.grid[i]ï¼šä¿å­˜çš„ç½‘æ ¼åç§»ï¼ˆgrid offsetsï¼‰ï¼Œå½¢çŠ¶ä¸€èˆ¬æ˜¯ (1, na, ny, nx, 2)ã€‚
# x[i]ï¼šæ¥è‡ªç¬¬ i ä¸ªæ£€æµ‹å±‚çš„è¾“å‡ºç‰¹å¾å›¾ï¼Œå½¢çŠ¶æ˜¯ (bs, na*no, ny, nx)ã€‚
# x[i].shape[2:4]ï¼šå–ç‰¹å¾å›¾çš„ (ny, nx)ï¼ˆé«˜åº¦å’Œå®½åº¦ï¼‰ã€‚
# self.grid[i].shape[2:4]ï¼šå–ä¹‹å‰ç¼“å­˜çš„ç½‘æ ¼çš„ (ny, nx)ã€‚
# ä¸¤è€…ä¸ä¸€è‡´æ—¶è¯´æ˜Žå½“å‰è¾“å…¥å›¾åƒå°ºå¯¸å’Œä¹‹å‰çš„ä¸ä¸€æ ·ï¼Œéœ€è¦é‡æ–°ç”Ÿæˆç½‘æ ¼ã€‚
                if self.dynamic or self.grid[i].shape[2:4] != x[i].shape[2:4]:
                    # grid[i]ï¼šæ¯ä¸ªç½‘æ ¼ç‚¹çš„åç§»åæ ‡ï¼Œå½¢çŠ¶ (1, na, ny, nx, 2)ã€‚
# anchor_grid[i]ï¼šå½“å‰å±‚é”šæ¡†ç¼©æ”¾åŽçš„å°ºå¯¸ï¼Œå½¢çŠ¶ (1, na, ny, nx, 2)ã€‚
# _make_grid ç”Ÿæˆæ–°çš„ç½‘æ ¼åæ ‡å’Œé”šæ¡†ç½‘æ ¼
# ç½‘ç»œè¾“å‡º (tx, ty, tw, th, confidence, class_prob)ï¼Œå…¶ä¸­ (tx, ty) æ˜¯ç›¸å¯¹ç½‘æ ¼ç‚¹å·¦ä¸Šè§’çš„åç§»ã€‚
# æ‰€ä»¥å¿…é¡»å…ˆç”Ÿæˆæ•´å¼ ç‰¹å¾å›¾çš„ç½‘æ ¼åæ ‡ï¼Œç”¨å®ƒå’Œç½‘ç»œè¾“å‡ºåšè§£ç ï¼Œå¾—åˆ°çœŸå®žå›¾åƒåæ ‡ã€‚
# ç‰¹å¾å›¾å…·ä½“å€¼ x[i] æ²¡å‚ä¸Ž grid ç”Ÿæˆï¼Œå®ƒåªæä¾›åç§»é‡ï¼Œå’Œ grid[i] ç»“åˆæ‰èƒ½ç®—å‡ºé¢„æµ‹æ¡†ã€‚
                    self.grid[i], self.anchor_grid[i] = self._make_grid(nx, ny, i)

                if isinstance(self, Segment):  # (boxes + masks)
                    # x[i] æ˜¯ç¬¬ i ä¸ªæ£€æµ‹å±‚çš„å·ç§¯è¾“å‡ºï¼Œshape ä¸€èˆ¬æ˜¯(bs, na, ny, nx, no)
                    #bs = batch size
# na = anchor æ•°é‡ï¼ˆé€šå¸¸æ˜¯ 3ï¼‰
# ny, nx = feature map çš„é«˜åº¦ã€å®½åº¦
# no = æ¯ä¸ª anchor çš„è¾“å‡ºç»´åº¦
# no = 4 + 1 + nc + nm
# 4 â†’ box åæ ‡ (x, y, w, h)
# 1 â†’ objectness
# nc â†’ åˆ†ç±»æ•°
# nm â†’ mask åŽŸåž‹ç³»æ•°ï¼ˆsegmentation head ç‰¹æœ‰ï¼‰
                    # æŠŠæ£€æµ‹å¤´çš„è¾“å‡º x[i] æŒ‰ç…§è¯­ä¹‰æ‹†åˆ†æˆä¸åŒçš„éƒ¨åˆ†
                    # åœ¨ç¬¬ 4 ç»´ï¼ˆdim=4ï¼‰åˆ‡æˆ 4 å—
                    # å‰ 2 ç»´ï¼šxy â†’ é¢„æµ‹æ¡†çš„ä¸­å¿ƒåæ ‡ (tx, ty)
# åŽ 2 ç»´ï¼šwh â†’ é¢„æµ‹æ¡†çš„å®½é«˜ (tw, th)
# self.nc + 1 ç»´ï¼šconf â†’ ç›®æ ‡ç½®ä¿¡åº¦ï¼ˆ1ï¼‰+ ç±»åˆ«æ¦‚çŽ‡ï¼ˆncï¼‰
# å‰©ä¸‹çš„ self.no - self.nc - 5 ç»´ï¼šmask â†’ åˆ†å‰²æŽ©ç ç³»æ•°
                    xy, wh, conf, mask = x[i].split((2, 2, self.nc + 1, self.no - self.nc - 5), 4)
                    # è¾“å…¥çš„ xy æ˜¯ç½‘ç»œé¢„æµ‹çš„åç§»é‡ (tx, ty)ï¼ŒèŒƒå›´æ˜¯å®žæ•°ã€‚
# sigmoid() â†’ æŠŠå®ƒåŽ‹ç¼©åˆ° (0,1)ã€‚
# * 2 â†’ æŠŠèŒƒå›´æ‰©å±•åˆ° (0,2)ï¼Œè¿™æ ·é¢„æµ‹ç‚¹ä¸ä»…å¯ä»¥è½åœ¨ç½‘æ ¼å•å…ƒå†…ï¼Œè¿˜èƒ½ç¨å¾®è¶…å‡ºã€‚
# + self.grid[i] â†’ åŠ ä¸Šå½“å‰ç½‘æ ¼çš„å·¦ä¸Šè§’åæ ‡ï¼Œå¾—åˆ°ç›¸å¯¹äºŽç‰¹å¾å›¾çš„ç»å¯¹ä½ç½®ã€‚
# * self.stride[i] â†’ æ˜ å°„å›žåŽŸå›¾åæ ‡ç³»ï¼ˆæ¯”å¦‚ stride=8ï¼Œåˆ™æ¯ä¸ª cell å¯¹åº”åŽŸå›¾ 8Ã—8 åƒç´ ï¼‰ã€‚
# ðŸ‘‰ ç»“æžœï¼šxy å°±æ˜¯é¢„æµ‹æ¡†ä¸­å¿ƒç‚¹åœ¨ åŽŸå›¾åæ ‡é‡Œçš„ä½ç½®ã€‚
                    xy = (xy.sigmoid() * 2 + self.grid[i]) * self.stride[i]  # xy
                    # è¾“å…¥çš„ wh æ˜¯ç½‘ç»œé¢„æµ‹çš„å®½é«˜åç§» (tw, th)ã€‚
# sigmoid() â†’ æŠŠå€¼é™åˆ¶åœ¨ (0,1)ã€‚
# * 2 â†’ èŒƒå›´ (0,2)ï¼Œä½¿å¾—å®½é«˜å¯ä»¥æ¯” anchor å°æˆ–å¤§ã€‚
# ** 2 â†’ å†å¹³æ–¹ï¼Œæ‰©å¤§åŠ¨æ€èŒƒå›´ï¼Œä½¿å¾—é¢„æµ‹æ¡†å¤§å°æ›´çµæ´»ï¼ˆæ—¢èƒ½é¢„æµ‹å°ç›®æ ‡ï¼Œä¹Ÿèƒ½é¢„æµ‹å¤§ç›®æ ‡ï¼‰ã€‚
# * self.anchor_grid[i] â†’ ä¸Žå¯¹åº”å±‚çš„ anchors ç›¸ä¹˜ï¼Œå¾—åˆ°æœ€ç»ˆçš„å®½é«˜ã€‚
# ðŸ‘‰ ç»“æžœï¼šwh å°±æ˜¯é¢„æµ‹æ¡†çš„å®½å’Œé«˜ï¼ˆåŽŸå›¾å°ºåº¦ï¼‰ã€‚
# **2 å’Œå‰é¢çš„ *2 è™½ç„¶å†™æ³•ä¸ä¸€æ ·ï¼Œä½†æœ¬è´¨éƒ½æ˜¯ ä¸ºäº†æ‰©å¤§é¢„æµ‹æ¡†çš„èŒƒå›´ï¼Œè®©æ¨¡åž‹å¯ä»¥æ›´çµæ´»åœ°é¢„æµ‹æ¡†å¤§å°ã€‚
                    wh = (wh.sigmoid() * 2) ** 2 * self.anchor_grid[i]  # wh
                    # æ‹¼æŽ¥æ‰€æœ‰é¢„æµ‹ç»“æžœï¼Œä»¥æœ€åŽä¸€ä¸ªç»´åº¦æ‹¼æŽ¥
                    y = torch.cat((xy, wh, conf.sigmoid(), mask), 4)
                else:  # Detect (boxes only)Detect æ¨¡å—ï¼ˆåªæ£€æµ‹ boxï¼‰
                    # é€»è¾‘ä¸Ž Segment ç±»ä¼¼ï¼Œåªæ˜¯æ²¡æœ‰ maskï¼š
                    xy, wh, conf = x[i].sigmoid().split((2, 2, self.nc + 1), 4)
                    xy = (xy * 2 + self.grid[i]) * self.stride[i]  # xy
                    wh = (wh * 2) ** 2 * self.anchor_grid[i]  # wh
                    y = torch.cat((xy, wh, conf), 4)
                    # æŠŠæ¯å±‚ feature map å±•å¹³ï¼š
# bsï¼šbatch size
# na * nx * nyï¼šæ¯å±‚æ‰€æœ‰ anchor çš„æ ¼å­æ•°
# noï¼šæ¯ä¸ª anchor çš„è¾“å‡ºç»´åº¦ (nc+5) æˆ– (nc+5+mask)
# ä¾¿äºŽä¸åŒå°ºåº¦çš„é¢„æµ‹ç»“æžœæ‹¼æŽ¥ã€‚
                z.append(y.view(bs, self.na * nx * ny, self.no))
        # è®­ç»ƒæ¨¡å¼
        # è¿”å›žåŽŸå§‹ feature map çš„å·ç§¯è¾“å‡ºï¼ˆæœªè§£ç ï¼‰ã€‚
# å› ä¸ºè®­ç»ƒæ—¶ loss å‡½æ•°ä¼šè‡ªå·±å¤„ç† raw è¾“å‡ºï¼Œä¸éœ€è¦è§£ç æˆåæ ‡ã€‚
# å¯¼å‡ºæ¨¡å¼
# torch.cat(z, 1)ï¼šæŠŠæ‰€æœ‰å°ºåº¦é¢„æµ‹ç»“æžœæ‹¼æŽ¥ï¼š
# z æ¯ä¸ªå…ƒç´ å½¢çŠ¶ (bs, na*ny*nx, no)
# æ‹¼æŽ¥åŽ (bs, sum(na*ny*nx), no) æ‹¼æŽ¥æ˜¯å¢žåŠ æ”¹ç»´åº¦å¤šä¸ªå€¼ï¼Œè€Œä¸æ˜¯æ±‚å’Œå¾—åˆ°ä¸€ä¸ªå€¼
# æ³¨æ„è¿”å›žçš„æ˜¯ä¸€ä¸ª tuple (tensor,)ï¼Œç¬¦åˆ ONNX/TensorRT å¯¼å‡ºè¦æ±‚ã€‚
# æ™®é€šæŽ¨ç†æ¨¡å¼
# è¿”å›ž æ‹¼æŽ¥åŽçš„é¢„æµ‹ + åŽŸå§‹ feature map listï¼š
# æ‹¼æŽ¥åŽçš„é¢„æµ‹ (bs, all_anchors, no)ï¼Œå¯ä»¥ç›´æŽ¥è¿›è¡Œ NMS å¾—åˆ°æœ€ç»ˆæ£€æµ‹æ¡†ã€‚
# åŽŸå§‹ feature map x å¯ä»¥ç”¨äºŽå…¶ä»–åŽå¤„ç†ï¼ˆæ¯”å¦‚å¯è§†åŒ–ã€Segmentation åˆ†æ”¯ç­‰ï¼‰ã€‚
        return x if self.training else (torch.cat(z, 1),) if self.export else (torch.cat(z, 1), x)

    '''===================3.ç›¸å¯¹åæ ‡è½¬æ¢åˆ°gridç»å¯¹åæ ‡ç³»============================'''
    # nx=20, ny=20ï¼šå½“å‰ç‰¹å¾å›¾çš„å®½ã€é«˜ï¼ˆä¾‹å¦‚ 20x20 ç½‘æ ¼ï¼‰ã€‚
# i=0ï¼šå½“å‰ç¬¬å‡ ä¸ªæ£€æµ‹å±‚ï¼ˆP3ã€P4ã€P5 ä¸­çš„ä¸€ä¸ªï¼‰ã€‚
# torch_1_10ï¼šå…¼å®¹ä¸åŒç‰ˆæœ¬çš„ PyTorchã€‚æ£€æµ‹å½“å‰ PyTorch çš„ç‰ˆæœ¬æ˜¯å¦å¤§äºŽç­‰äºŽ 1.10.0
    def _make_grid(self, nx=20, ny=20, i=0, torch_1_10=check_version(torch.__version__, '1.10.0')):
        # ç¡®ä¿ç”Ÿæˆçš„ tensor å’Œ anchors çš„è®¾å¤‡ (CPU/GPU) ä»¥åŠæ•°æ®ç±»åž‹ä¸€è‡´ã€‚
        d = self.anchors[i].device
        t = self.anchors[i].dtype
        # 1 â†’ batch ç»´åº¦ï¼ˆè¿™é‡Œå…ˆå ä½ï¼‰
# na â†’ æ¯ä¸ªç½‘æ ¼ç‚¹æœ‰å¤šå°‘ä¸ª anchor
# ny, nx â†’ ç‰¹å¾å›¾çš„å¤§å°
# 2 â†’ (x, y) ä¸¤ä¸ªåæ ‡
        shape = 1, self.na, ny, nx, 2  # grid shape
        # torch.arange(ny) â†’ [0, 1, 2, ..., ny-1]
# torch.arange(nx) â†’ [0, 1, 2, ..., nx-1]
        y, x = torch.arange(ny, device=d, dtype=t), torch.arange(nx, device=d, dtype=t)
# yv æ˜¯çºµå‘åæ ‡ (y),æ¯è¡Œç›¸åŒ
# xv æ˜¯æ¨ªå‘åæ ‡ (x),æ¯åˆ—ç›¸åŒ
        yv, xv = torch.meshgrid(y, x, indexing='ij') if torch_1_10 else torch.meshgrid(y, x)  # torch>=0.7 compatibility
        # torch.stack((xv, yv), 2) â†’ åœ¨æœ€åŽä¸€ä¸ªç»´åº¦æ‹¼æŽ¥æˆ (x, y) åæ ‡å¯¹ï¼Œå±žäºŽè¿½åŠ ç¬¬ä¸‰ä¸ªç»´åº¦
        # .expand(shape) â†’ æ‰©å±•æˆ (1, na, ny, nx, 2) å½¢çŠ¶ï¼Œæ¯ä¸ªç½‘æ ¼ç‚¹éƒ½è¦åŒ¹é… na ä¸ª anchorã€‚
# -0.5 â†’ åšä¸€ä¸ªå°çš„åç§»ï¼Œè®©é¢„æµ‹æ›´å±…ä¸­ã€‚
# grid çš„ä½œç”¨ï¼šå‘Šè¯‰æ¨¡åž‹æ¯ä¸ªé¢„æµ‹æ˜¯åœ¨ç‰¹å¾å›¾çš„å“ªä¸ªç½‘æ ¼ç‚¹ä¸Šã€‚
        grid = torch.stack((xv, yv), 2).expand(shape) - 0.5  # add grid offset, i.e. y = 2.0 * x - 0.5
        #self.anchors[i] â†’ è¯¥æ£€æµ‹å±‚çš„ anchors å°ºå¯¸ (ç›¸å¯¹å¤§å°)ã€‚
# self.stride[i] â†’ è¯¥æ£€æµ‹å±‚ç›¸å¯¹äºŽè¾“å…¥å›¾ç‰‡çš„ç¼©æ”¾æ­¥é•¿ï¼ˆæ¯”å¦‚ P3 çš„ stride=8ï¼ŒP4=16ï¼ŒP5=32ï¼‰ã€‚
# .view((1, self.na, 1, 1, 2)) â†’ è°ƒæ•´å½¢çŠ¶ï¼Œæ–¹ä¾¿åŽç»­å’Œ grid å¯¹é½ã€‚
# .expand(shape) â†’ è®©æ¯ä¸ª (x, y) ç½‘æ ¼ç‚¹éƒ½å¯¹åº”è¿™å‡ ä¸ª anchorsã€‚
# âœ… anchor_grid çš„ä½œç”¨ï¼šè¡¨ç¤ºæ¯ä¸ªç½‘æ ¼ç‚¹çš„ anchor æ¡†çš„çœŸå®žåƒç´ å¤§å°ã€‚
# .expand(shape)å¯¹åº”æ¯ä¸ªç½‘æ ¼ç‚¹ï¼Œéƒ½æœ‰ä¸€ä»½ anchor (w, h)
# æ³¨æ„ expand ä¸å¤åˆ¶æ•°æ®ï¼Œåªæ˜¯è®©æ¯ä¸ªä½ç½®å…±äº«åŒä¸€ä¸ª anchor å°ºå¯¸
        anchor_grid = (self.anchors[i] * self.stride[i]).view((1, self.na, 1, 1, 2)).expand(shape)
        return grid, anchor_grid


class Segment(Detect):
    # YOLOv5 Segment head for segmentation models
    def __init__(self, nc=80, anchors=(), nm=32, npr=256, ch=(), inplace=True):
        super().__init__(nc, anchors, ch, inplace)
        self.nm = nm  # number of masks
        self.npr = npr  # number of protos
        self.no = 5 + nc + self.nm  # number of outputs per anchor
        self.m = nn.ModuleList(nn.Conv2d(x, self.no * self.na, 1) for x in ch)  # output conv
        self.proto = Proto(ch[0], self.npr, self.nm)  # protos
        self.detect = Detect.forward

    def forward(self, x):
        p = self.proto(x[0])
        x = self.detect(self, x)
        return (x, p) if self.training else (x[0], p) if self.export else (x[0], p, x[1])


class BaseModel(nn.Module):
    # YOLOv5 base model
    def forward(self, x, profile=False, visualize=False):
        return self._forward_once(x, profile, visualize)  # single-scale inference, train

    def _forward_once(self, x, profile=False, visualize=False):
        # y ç”¨æ¥ä¿å­˜ä¸­é—´å±‚çš„è¾“å‡ºï¼ˆåªæœ‰éœ€è¦ä¿å­˜çš„æ‰å­˜ï¼Œä¸æ˜¯æ¯ä¸€å±‚éƒ½ä¿å­˜ï¼‰ã€‚
# dt ç”¨æ¥å­˜å‚¨ profilingï¼ˆå±‚è€—æ—¶ä¿¡æ¯ï¼‰ï¼Œåªæœ‰åœ¨ profile=True æ—¶æ‰ç”¨ã€‚
        y, dt = [], []  # outputs
        # self.model æ˜¯ä¸€ä¸ª nn.ModuleListï¼ŒæŒ‰é¡ºåºå­˜æ”¾ YOLO ç½‘ç»œçš„å„ä¸ªå­æ¨¡å—ï¼ˆå·ç§¯å±‚ã€C3ã€Detect å±‚ç­‰ï¼‰ã€‚
# å¾ªçŽ¯é€å±‚æ‰§è¡Œ
        for m in self.model:
            if m.f != -1:  # if not from previous layer
                # å…¶ä¸­ y æ˜¯ä¸ªåˆ—è¡¨ï¼Œä¿å­˜äº†æ‰€æœ‰å‰é¢å±‚çš„è¾“å‡º
                # x ä»£è¡¨ ä¸Šä¸€å±‚çš„è¾“å‡º
                # m.f å¦‚æžœæ˜¯ intï¼ˆæ¯”å¦‚ 6ï¼‰ï¼Œå°±è¡¨ç¤ºâ€œå–ç¬¬ 6 å±‚çš„è¾“å‡ºâ€ã€‚
# x = y[m.f] å°±èƒ½å¾—åˆ°è¯¥å±‚çš„ç‰¹å¾å›¾ã€‚
# å¦‚æžœ j == -1ï¼Œå°±å–å½“å‰çš„ xï¼ˆä¹Ÿå°±æ˜¯ä¸Šä¸€å±‚çš„è¾“å‡ºï¼‰ã€‚
# å¦‚æžœ j != -1ï¼Œå°±å– y[j]ï¼ˆç¬¬ j å±‚çš„è¾“å‡ºï¼‰ã€‚
# æœ€ç»ˆå¾—åˆ°ä¸€ä¸ª listï¼Œä½œä¸ºæœ¬å±‚çš„è¾“å…¥ï¼Œé€šå¸¸åŽé¢ä¼šæ‹¼æŽ¥ï¼ˆæ¯”å¦‚ C3 æ¨¡å—é‡Œçš„ Concatï¼‰
# å¦‚ï¼šfrom: [6, 9, 10, -1]ï¼Œè¡¨ç¤ºè¾“å…¥æ¥è‡ªç¬¬ 6ã€9ã€10 å±‚ä»¥åŠä¸Šä¸€å±‚ã€‚
# x = [y[6], y[9], y[10], x]
                x = y[m.f] if isinstance(m.f, int) else [x if j == -1 else y[j] for j in m.f]  # from earlier layers
            if profile:
                # å¦‚æžœ profile=Trueï¼Œå°±è°ƒç”¨ _profile_one_layer ç»Ÿè®¡è¯¥å±‚çš„ è®¡ç®—è€—æ—¶ã€FLOPs ç­‰ä¿¡æ¯ï¼Œå­˜åˆ° dt
                self._profile_one_layer(m, x, dt)
            # å°†è¾“å…¥ x é€å…¥å½“å‰å±‚ mï¼Œå¾—åˆ°è¯¥å±‚è¾“å‡º
            x = m(x)  # run
            # self.save æ˜¯ä¸ªåˆ—è¡¨ï¼Œè®°å½•å“ªäº›å±‚çš„è¾“å‡ºéœ€è¦ä¿å­˜ï¼ˆå› ä¸ºåŽç»­ç½‘ç»œè¿˜ä¼šç”¨åˆ°ï¼‰ã€‚
# å¦‚æžœè¯¥å±‚ m.iï¼ˆå±‚ç´¢å¼•å·ï¼‰åœ¨ self.save é‡Œï¼Œå°±æŠŠè¾“å‡º x å­˜åˆ° yï¼Œå¦åˆ™å­˜ Noneï¼ˆèŠ‚çœå†…å­˜ï¼‰
            y.append(x if m.i in self.save else None)  # save output
            if visualize:
                # å¦‚æžœ visualize=Trueï¼Œè°ƒç”¨ feature_visualization ä¿å­˜è¯¥å±‚ç‰¹å¾å›¾ï¼Œç”¨äºŽå¯è§†åŒ–
                feature_visualization(x, m.type, m.i, save_dir=visualize)
        # è¿”å›žæœ€åŽä¸€å±‚çš„è¾“å‡ºï¼ˆä¸€èˆ¬æ˜¯ Detect å±‚çš„é¢„æµ‹ç»“æžœï¼‰
        return x

# ç»Ÿè®¡æ¨¡åž‹å•å±‚è®¡ç®—å¼€é”€ï¼ˆFLOPsã€æŽ¨ç†æ—¶é—´ã€å‚æ•°é‡ï¼‰ çš„å·¥å…·å‡½æ•°ï¼Œé€šå¸¸ç”¨äºŽè°ƒè¯•æˆ–æ€§èƒ½åˆ†æžï¼Œä¸å½±å“æ¨¡åž‹æŽ¨ç†
    def _profile_one_layer(self, m, x, dt):
        # åˆ¤æ–­å½“å‰å±‚ m æ˜¯å¦æ˜¯ æœ€åŽä¸€å±‚ï¼ˆé€šå¸¸æ˜¯ Detectï¼‰
# å¦‚æžœæ˜¯æœ€åŽä¸€å±‚ï¼Œå¯èƒ½éœ€è¦å¤åˆ¶è¾“å…¥ï¼ˆx.copy()ï¼‰ï¼Œé¿å… inplace æ“ä½œå½±å“ç»Ÿè®¡ç»“æžœã€‚
        c = m == self.model[-1]  # is final layer, copy input as inplace fix
        # ä½¿ç”¨ thop åº“ç»Ÿè®¡ FLOPsï¼ˆæµ®ç‚¹è¿ç®—æ¬¡æ•°ï¼‰
# inputs=(x.copy() if c else x,)ï¼šæœ€åŽä¸€å±‚ä½¿ç”¨æ‹·è´è¾“å…¥
# [0] å– FLOPs æ•°å€¼ï¼ˆthop.profile è¿”å›ž (FLOPs, params)ï¼‰
# /1E9 è½¬ä¸º GFLOPs
# * 2 æ˜¯å› ä¸º YOLO è®¡ç®—æ—¶å‰å‘+åå‘ç»Ÿè®¡
# å¦‚æžœæ²¡æœ‰å®‰è£… thopï¼Œå°±è¿”å›ž 0
        o = thop.profile(m, inputs=(x.copy() if c else x,), verbose=False)[0] / 1E9 * 2 if thop else 0  # FLOPs
        # æµ‹å‰å‘æŽ¨ç†æ—¶é—´
# å¾ªçŽ¯ 10 æ¬¡ï¼Œç¡®ä¿æµ‹é‡ç¨³å®š
# time_sync() æ˜¯åŒæ­¥ GPU/CPU æ—¶é—´çš„å‡½æ•°
# dt.append(...) å­˜å‚¨è€—æ—¶ï¼Œå•ä½ä¸ºæ¯«ç§’ï¼ˆä¹˜ä»¥ 100ï¼Œè¿™é‡Œæ˜¯ä¸ºäº†æ”¾å¤§ä¾¿äºŽå±•ç¤ºï¼‰
        t = time_sync()
        for _ in range(10):
            m(x.copy() if c else x)
        dt.append((time_sync() - t) * 100)
        # å¦‚æžœæ˜¯ç¬¬ä¸€å±‚ï¼Œæ‰“å°è¡¨å¤´
        if m == self.model[0]:
            LOGGER.info(f"{'time (ms)':>10s} {'GFLOPs':>10s} {'params':>10s}  module")
        # æ‰“å°å½“å‰å±‚çš„ç»Ÿè®¡ä¿¡æ¯ï¼š
# dt[-1] â†’ æŽ¨ç†è€—æ—¶ï¼ˆmsï¼‰
# o â†’ FLOPsï¼ˆGFLOPsï¼‰
# m.np â†’ å‚æ•°æ•°é‡
# m.type â†’ æ¨¡å—ç±»åž‹ï¼ˆConv, C3, Detect ç­‰ï¼‰
        LOGGER.info(f'{dt[-1]:10.2f} {o:10.2f} {m.np:10.0f}  {m.type}')
        if c:
            # å¦‚æžœæ˜¯æœ€åŽä¸€å±‚ï¼Œæ‰“å° æ€»è€—æ—¶
            LOGGER.info(f"{sum(dt):10.2f} {'-':>10s} {'-':>10s}  Total")

    '''å°†Conv2d+BNè¿›è¡Œèžåˆ'''
    def fuse(self):  # fuse model Conv2d() + BatchNorm2d() layers
        LOGGER.info('Fusing layers... ')
        for m in self.model.modules():
            # éåŽ†æ¨¡åž‹çš„æ¯ä¸ªæ¨¡å— mï¼š
# åªå¯¹å·ç§¯æ¨¡å— Conv æˆ–æ·±åº¦å¯åˆ†å·ç§¯ DWConv å¤„ç†ã€‚
# å¿…é¡»æœ‰ bn å±žæ€§ï¼ˆå³æœ‰ BatchNorm å±‚
            if isinstance(m, (Conv, DWConv)) and hasattr(m, 'bn'):
                # è°ƒç”¨ fuse_conv_and_bn å‡½æ•°ï¼Œå°†å·ç§¯æƒé‡å’Œ BN å‚æ•°èžåˆï¼Œç”Ÿæˆæ–°çš„å·ç§¯å±‚ã€‚
                # å¯ä»¥å˜æ¢ä¸ºç­‰æ•ˆçš„å·ç§¯æƒé‡å’Œ biasï¼Œç›´æŽ¥ç”¨åœ¨å·ç§¯è¾“å‡ºä¸Šã€‚
                m.conv = fuse_conv_and_bn(m.conv, m.bn)  # update conv
                # èžåˆåŽ BN å·²ä¸éœ€è¦ï¼Œåˆ é™¤ bn å±žæ€§ï¼Œå‡å°‘æŽ¨ç†å¼€é”€ã€‚
                delattr(m, 'bn')  # remove batchnorm
                # æ›¿æ¢å·ç§¯æ¨¡å—çš„ forward æ–¹æ³•ï¼š
# åŽŸæ¥çš„ forward ä¼šæ‰§è¡Œ conv -> bn -> act
# èžåˆåŽåªæ‰§è¡Œ conv -> actï¼ˆä¸å†è°ƒç”¨ BNï¼‰
                m.forward = m.forward_fuse  # update forward
        # æ‰“å°æ¨¡åž‹ä¿¡æ¯ï¼Œæ–¹ä¾¿ç¡®è®¤ Conv+BN å·²ç»èžåˆã€‚
        self.info()
        # è¿”å›žå·²ç»èžåˆåŽçš„æ¨¡åž‹å¯¹è±¡ï¼Œå¯ä»¥ç»§ç»­æŽ¨ç†æˆ–ä¿å­˜
        return self

    '''æ‰“å°æ¨¡åž‹ç»“æž„ä¿¡æ¯'''
    def info(self, verbose=False, img_size=640):  # print model information
        # è°ƒç”¨torch_utils.pyä¸‹model_infoå‡½æ•°æ‰“å°æ¨¡åž‹ä¿¡æ¯
        model_info(self, verbose, img_size)

    '''å°†æ¨¡å—è½¬ç§»åˆ° CPU/ GPUä¸Š'''
    # PyTorch é»˜è®¤ä¼šæŠŠ å‚æ•°ï¼ˆParametersï¼‰ å’Œ æ³¨å†Œçš„ç¼“å†²ï¼ˆregister_bufferï¼‰ è‡ªåŠ¨è½¬æ¢ï¼Œä½†æœ‰äº›æ¨¡å—é‡Œè¿˜æŒæœ‰æ™®é€šå¼ é‡å±žæ€§ï¼ˆæ—¢ä¸æ˜¯å‚æ•°ä¹Ÿä¸æ˜¯ bufferï¼‰ï¼Œè¿™äº›ä¹Ÿéœ€è¦åŒæ­¥è½¬æ¢ï¼Œæ­¤å¤„å°±æ˜¯åšè¿™ä»¶äº‹
    # fn æ˜¯ä¸€ä¸ªâ€œå¯¹å¼ é‡åšè½¬æ¢â€çš„å‡½æ•°ï¼ˆç”± PyTorch åœ¨å†…éƒ¨ä¼ å…¥
    def _apply(self, fn):
        # Apply to(), cpu(), cuda(), half() to model tensors that are not parameters or registered buffers
        # è¯¥è°ƒç”¨ä¼šé€’å½’å°† fn åº”ç”¨äºŽæ‰€æœ‰ Parameter å’Œè¢« register_buffer æ³¨å†Œçš„å¼ é‡ï¼ˆä»¥åŠå­æ¨¡å—çš„ _applyï¼‰ã€‚
# super()._apply(fn) ä¼šè¿”å›žå·²ç»è¢«è½¬æ¢åŽçš„æ¨¡å—å¯¹è±¡ï¼ˆé€šå¸¸å°±æ˜¯ self æœ¬èº«ï¼‰ï¼Œå› æ­¤æŠŠç»“æžœé‡æ–°èµ‹å›ž self æ˜¯å®‰å…¨ä¸”å¸¸è§çš„åšæ³•
        self = super()._apply(fn)
        # å–æ¨¡åž‹çš„æœ€åŽä¸€ä¸ªå­æ¨¡å—ï¼ˆYOLO çš„å®žçŽ°é‡Œæœ€åŽä¸€å±‚é€šå¸¸æ˜¯ Detect æˆ– Segmentï¼‰ã€‚
# ç›®çš„æ˜¯å¯¹è¯¥æ£€æµ‹å¤´ä¸­è‡ªå®šä¹‰æŒæœ‰ä½†æœªæ³¨å†Œä¸º buffer çš„å¼ é‡åšé¢å¤–è½¬æ¢ï¼ˆä¾‹å¦‚ï¼šstride, grid, anchor_gridï¼‰ã€‚
        m = self.model[-1]  # Detect()
        # è¿™ä¸¤ä¸ªæ¨¡å—æŒæœ‰ä¸€äº›è¿è¡Œæ—¶ç¼“å­˜ï¼ˆgrid, anchor_grid, strideï¼‰ï¼Œè¿™äº›å¼ é‡ä¸æ˜¯ nn.Parameter ä¹Ÿä¸æ˜¯ç”¨ register_buffer æ³¨å†Œçš„ï¼Œæ‰€ä»¥çˆ¶ç±» _apply ä¸ä¼šå¤„ç†å®ƒä»¬â€”â€”å› æ­¤è¿™é‡Œè¡¥ä¸Šã€‚
        if isinstance(m, (Detect, Segment)):
            # Detect è§£ç è®¡ç®—é‡Œä¼šåš (xy*2 + grid) * strideï¼Œå¦‚æžœ stride ä¿æŒåœ¨ CPU/FP32 è€Œè¾“å…¥ç‰¹å¾åœ¨ GPU/FP16ï¼Œä¼šå¯¼è‡´è®¾å¤‡æˆ– dtype ä¸åŒ¹é…é”™è¯¯ï¼ˆä¾‹å¦‚ expected scalar type Half but found Float æˆ– device mismatchï¼‰ã€‚
            m.stride = fn(m.stride)
            # m.grid æ˜¯ä¸€ä¸ª listï¼ˆæ¯ä¸ªå°ºåº¦ä¸€ä¸ª tensorï¼Œå¯èƒ½æœ€åˆæ˜¯ torch.empty(0)ï¼Œå®žé™…ä¼šåœ¨ç¬¬ä¸€æ¬¡ forward æ—¶ replace æˆå®žé™…å¼ é‡ï¼‰ï¼Œè¿™é‡Œå¯¹ m.grid ä¸­æ¯ä¸ª tensor åº”ç”¨ fnï¼Œå¹¶æŠŠç»“æžœè½¬æˆ list ä¿å­˜
            m.grid = list(map(fn, m.grid))
            if isinstance(m.anchor_grid, list):
                # anchor_grid åœ¨è§£ç  (wh * 2)^2 * anchor_grid æ—¶ä¼šè¢«ç”¨åˆ°ï¼Œæ‰€ä»¥ä¹Ÿå¿…é¡»ä¸Žç‰¹å¾åŒ device/dtypeã€‚
                m.anchor_grid = list(map(fn, m.anchor_grid))
        # è¿”å›žå¤„ç†åŽçš„æ¨¡å—å¯¹è±¡ï¼Œä¾›è°ƒç”¨ç«¯ç»§ç»­ä½¿ç”¨ï¼ˆè¿™ä¸Ž nn.Module._apply çš„è¡Œä¸ºä¸€è‡´ï¼‰ã€‚
# è¿™æ ·é“¾å¼è°ƒç”¨ model.to(...).eval() ç­‰ä»ç„¶å¯ç”¨ã€‚
        return self

# Modelç±»æ˜¯æ•´ä¸ªæ¨¡åž‹çš„æž„é€ æ¨¡å—éƒ¨åˆ†ã€‚ é€šè¿‡è‡ªå®šä¹‰YOLOæ¨¡åž‹ç±» ï¼Œç»§æ‰¿torch.nn.Moduleã€‚ä¸»è¦ä½œç”¨æ˜¯æŒ‡å®šæ¨¡åž‹çš„yamlæ–‡ä»¶ä»¥åŠä¸€ç³»åˆ—çš„è®­ç»ƒå‚æ•°ã€‚
class DetectionModel(BaseModel):
    '''===================1.__init__å‡½æ•°==========================='''
    # YOLOv5 detection model
    def __init__(self, cfg='yolov5s.yaml', ch=3, nc=None, anchors=None):  # model, input channels, number of classes
        super().__init__()
        # å¦‚æžœ cfg å·²ç»æ˜¯å­—å…¸
        if isinstance(cfg, dict):
            # ç›´æŽ¥èµ‹å€¼ç»™ self.yamlï¼ŒåŽç»­ç”¨è¿™ä¸ªå­—å…¸æž„å»ºæ¨¡åž‹ç»“æž„ã€‚
            self.yaml = cfg  # model dict
        else:  # is *.yaml
            # å¦‚æžœ cfg æ˜¯ *.yaml æ–‡ä»¶
            import yaml  # for torch hub
            # cfg æ˜¯ yaml æ–‡ä»¶è·¯å¾„ï¼Œæ¯”å¦‚ "yolov5s.yaml"ã€‚
# self.yaml_file ä¿å­˜æ–‡ä»¶åï¼Œç”¨äºŽæ—¥å¿—æˆ–è°ƒè¯•ã€‚
            self.yaml_file = Path(cfg).name
            # yaml.safe_load(f)ï¼šæŠŠ yaml æ–‡ä»¶è§£æžæˆ Python å­—å…¸ã€‚
# self.yaml å°±å¾—åˆ°å’Œç›´æŽ¥ä¼ å…¥å­—å…¸ä¸€æ ·çš„ç»“æž„ï¼Œå¯ä»¥ç›´æŽ¥ç”¨äºŽ parse_model æž„å»ºç½‘ç»œ
            with open(cfg, encoding='ascii', errors='ignore') as f:
                self.yaml = yaml.safe_load(f)  # model dict

        # Define model
        # å¦‚æžœ yaml ä¸­å®šä¹‰äº† chï¼ˆè¾“å…¥é€šé“åˆ—è¡¨ï¼‰ï¼Œå°±ç”¨å®ƒã€‚
# å¦åˆ™ç”¨å‡½æ•°å‚æ•° chï¼ˆé€šå¸¸æ˜¯ [3]ï¼ŒRGB è¾“å…¥ï¼‰
        ch = self.yaml['ch'] = self.yaml.get('ch', ch)  # input channels
# nc æ˜¯å‡½æ•°ä¼ å…¥çš„ç±»åˆ«æ•°å‚æ•°ã€‚
# å¦‚æžœä¼ å…¥çš„ nc ä¸ä¸ºç©ºå¹¶ä¸”ä¸Ž yaml ä¸­ä¸åŒï¼Œåˆ™è¦†ç›– yaml çš„å€¼ã€‚
# æ–¹ä¾¿ç”¨æˆ·åœ¨åˆå§‹åŒ–æ¨¡åž‹æ—¶åŠ¨æ€æ”¹å˜ç±»åˆ«æ•°
        if nc and nc != self.yaml['nc']:
            LOGGER.info(f"Overriding model.yaml nc={self.yaml['nc']} with nc={nc}")
            self.yaml['nc'] = nc  # override yaml value
        if anchors:
            # åŒæ ·ï¼Œå…è®¸ä¼ å…¥è‡ªå®šä¹‰ anchorsã€‚
# ä½¿ç”¨ round(anchors) è¿›è¡Œå››èˆäº”å…¥ï¼Œç¡®ä¿ anchor æ˜¯æ•´æ•°ã€‚
# æ‰“å°æ—¥å¿—æé†’ç”¨æˆ·è¦†ç›–äº†åŽŸæœ‰ yaml çš„ anchorsã€‚
            LOGGER.info(f'Overriding model.yaml anchors with anchors={anchors}')
            self.yaml['anchors'] = round(anchors)  # override yaml value
        # è§£æžæ¨¡åž‹ï¼Œself.modelæ˜¯è§£æžåŽçš„æ¨¡åž‹ self.saveæ˜¯æ¯ä¸€å±‚ä¸Žä¹‹ç›¸è¿žçš„å±‚
        self.model, self.save = parse_model(deepcopy(self.yaml), ch=[ch])  # model, savelist
        # ç”¨æ•°å­—å­—ç¬¦ä¸² [0, 1, 2, ..., nc-1] ä½œä¸ºç±»åˆ«åç§°ã€‚
# å¦‚æžœç”¨æˆ·æ²¡æœ‰æä¾› namesï¼Œå°±ä½¿ç”¨é»˜è®¤
        self.names = [str(i) for i in range(self.yaml['nc'])]  # default names
        # å¦‚æžœ yaml ä¸­æœ‰ "inplace" å­—æ®µï¼Œå°±ä½¿ç”¨å®ƒçš„å€¼ï¼ˆTrue æˆ– Falseï¼‰ã€‚
# å¦‚æžœæ²¡æœ‰ï¼Œå°±é»˜è®¤è¿”å›ž True
        self.inplace = self.yaml.get('inplace', True)

        # Build strides, anchors
        # self.model[-1]ï¼šYOLOv5 æ¨¡åž‹çš„æœ€åŽä¸€å±‚ï¼Œä¸€èˆ¬æ˜¯ Detect æˆ– Segment å±‚ã€‚
# åªæœ‰æœ€åŽä¸€å±‚æ‰éœ€è¦å¤„ç† stride å’Œ anchorsã€‚
        m = self.model[-1]  # Detect()
        if isinstance(m, (Detect, Segment)):
            # s = 256ï¼šä¸€ä¸ªåˆå§‹åŒ–å¤§å°ï¼Œç”¨äºŽæŽ¨ä¸€æ¬¡ dummy inputï¼Œè®¡ç®— strideã€‚
            s = 256  # 2x min stride
            m.inplace = self.inplace
            # å¯¹ Segment å±‚ï¼Œforward(x) ä¼šè¿”å›ž (boxes+mask, feature_maps)ï¼Œå– [0] åªè¦é¢„æµ‹ã€‚
# å¯¹ Detect å±‚ï¼Œç›´æŽ¥è¿”å›ž forward(x)ã€‚
# è¿™é‡Œçš„ forward å°±æ˜¯ä¸€ä¸ªå‡½æ•°å¯¹è±¡ã€‚lambda x: ... å®šä¹‰äº†ä¸€ä¸ªåŒ¿åå‡½æ•°ã€‚
            forward = lambda x: self.forward(x)[0] if isinstance(m, Segment) else self.forward(x)
            # forward é€šè¿‡ backbone+neck+headï¼Œå¾—åˆ°æ¯ä¸ªå°ºåº¦ç‰¹å¾å›¾ x[i]ã€‚
# s / x.shape[-2] â†’ æ¯ä¸ªæ£€æµ‹å±‚çš„ strideï¼ˆé€šå¸¸æ˜¯ [8,16,32] å¯¹åº” P3,P4,P5ï¼‰ã€‚
# è¾“å…¥å°ºå¯¸/è¾“å‡ºç‰¹å¾å›¾å°ºå¯¸ = stride
            m.stride = torch.tensor([s / x.shape[-2] for x in forward(torch.zeros(1, ch, s, s))])  # forward
            # ç¡®ä¿ anchors ä¸Ž stride çš„é¡ºåºä¸€è‡´ï¼ˆå°ç›®æ ‡ anchor å¯¹åº”å° strideï¼Œå³é«˜åˆ†è¾¨çŽ‡ç‰¹å¾å›¾ï¼‰ã€‚
# é¿å…é¢„æµ‹æ¡†å’Œ anchor å¯¹ä¸ä¸Šã€‚
            check_anchor_order(m)
            # æŠŠ anchor ä»ŽåŽŸå›¾å°ºåº¦å½’ä¸€åŒ–åˆ° ç‰¹å¾å›¾å°ºåº¦ï¼š
# anchor åœ¨åŽŸå›¾ä¸Šæ˜¯åƒç´ å°ºå¯¸
# é™¤ä»¥ stride åŽï¼Œå¾—åˆ°æ¯ä¸ªç‰¹å¾å›¾æ ¼å­å¯¹åº”çš„ anchor å°ºå¯¸
# è¿™æ ·åŽç»­é¢„æµ‹å…¬å¼ (wh * anchor_grid) å°±æ­£ç¡®
# view(-1,1,1)
# å…ˆæŠŠ stride ä»Ž (3,) è½¬æˆ (3,1,1)ï¼Œæ–¹ä¾¿å’Œ (3,3,2) å½¢çŠ¶çš„ anchors å¹¿æ’­ç›¸é™¤ã€‚
            m.anchors /= m.stride.view(-1, 1, 1)
            # å°† stride ä¿å­˜åˆ°æ¨¡åž‹å¯¹è±¡é‡Œï¼Œæ–¹ä¾¿åŽç»­ NMS å’Œ decode ä½¿ç”¨
            self.stride = m.stride
            # å¯¹ Detect å±‚å·ç§¯è¾“å‡ºçš„åç½®è¿›è¡Œåˆå§‹åŒ–ï¼š
# åˆ†ç±»åç½®é€šå¸¸åˆå§‹åŒ–ä¸ºä½Žæ¦‚çŽ‡ï¼ˆæ¯”å¦‚ 0.01ï¼‰ï¼ŒåŠ å¿«è®­ç»ƒæ”¶æ•›ã€‚
# ç½®ä¿¡åº¦åç½®ä¹Ÿä¼šåˆå§‹åŒ–ä¸ºå°å€¼ï¼Œå‡å°‘æ—©æœŸå‡é˜³æ€§ã€‚
            self._initialize_biases()  # only run once

        # Init weights, biases
        # åˆå§‹åŒ–æƒé‡ä¿è¯æ¨¡åž‹å‚æ•°åœ¨è®­ç»ƒå‰å¤„äºŽåˆé€‚èŒƒå›´ã€‚
        initialize_weights(self)
        # æ‰“å°æ¨¡åž‹ä¿¡æ¯
        # è¾“å‡ºé€šå¸¸åŒ…æ‹¬ï¼š
# å±‚ç±»åž‹å’Œé¡ºåº
# æ¯å±‚è¾“å…¥/è¾“å‡ºé€šé“
# å‚æ•°æ•°é‡ï¼ˆweightsï¼‰
# æ¨¡åž‹æ€»å‚æ•°é‡å’Œå¯è®­ç»ƒå‚æ•°é‡
        self.info()
        # ä»…ä»…æ˜¯æ‰“å°ä¸€ä¸ªç©ºè¡Œï¼Œç¾ŽåŒ–æ—¥å¿—è¾“å‡ºã€‚
        LOGGER.info('')

    # xï¼šè¾“å…¥å¼ é‡ (batch, channels, height, width)
# augmentï¼šæ˜¯å¦ä½¿ç”¨æ•°æ®å¢žå¼ºæŽ¨ç†ï¼ˆTTA, Test Time Augmentationï¼‰
# profileï¼šæ˜¯å¦å¯¹æ¯å±‚åšè€—æ—¶ç»Ÿè®¡
# visualizeï¼šæ˜¯å¦å¯è§†åŒ–ä¸­é—´ç‰¹å¾å›¾
    def forward(self, x, augment=False, profile=False, visualize=False):
        # æ˜¯å¦ä½¿ç”¨å¢žå¼ºæŽ¨ç†
        if augment:
            # _forward_augment ç”¨äºŽ å¢žå¼ºæŽ¨ç†ï¼Œé€šå¸¸ä¼šï¼š
# å¯¹è¾“å…¥å›¾åƒåšæ°´å¹³ç¿»è½¬ã€å°ºåº¦ç¼©æ”¾ç­‰å¤šç§å˜æ¢
# åˆ†åˆ« forwardï¼Œæ¯ä¸ªè¾“å‡ºè§£ç åˆ°åŽŸå›¾åæ ‡
# æœ€åŽæŠŠå¤šä¸ªé¢„æµ‹ç»“æžœèžåˆï¼ˆå¦‚ NMSï¼‰
            return self._forward_augment(x)  # augmented inference, None
        # æ‰§è¡Œ æ ‡å‡†ä¸€æ¬¡æ€§ forward
        # ä¾æ¬¡é€šè¿‡ backbone â†’ neck â†’ head â†’ Detect
# è§£ç é¢„æµ‹æ¡† (boxes + scores)
# æ ¹æ® profile è¾“å‡ºè€—æ—¶
# æ ¹æ® visualize å¯é€‰æ‹©è¾“å‡ºä¸­é—´ feature map
        return self._forward_once(x, profile, visualize)  # single-scale inference, train

    # é€šè¿‡å¯¹è¾“å…¥å›¾åƒåšå¤šå°ºåº¦ã€å¤šç¿»è½¬é¢„æµ‹ï¼Œå†èžåˆç»“æžœæé«˜æ£€æµ‹ç²¾åº¦
    def _forward_augment(self, x):
        # èŽ·å–è¾“å…¥å°ºå¯¸
        img_size = x.shape[-2:]  # height, width
        # sï¼šç¼©æ”¾æ¯”ä¾‹
# 1 â†’ åŽŸå›¾
# 0.83 â†’ ç¼©å° 17%
# 0.67 â†’ ç¼©å° 33%
        s = [1, 0.83, 0.67]  # scales
        # fï¼šç¿»è½¬æ–¹å¼
# None â†’ ä¸ç¿»è½¬
# 3 â†’ å·¦å³ç¿»è½¬
# 2 â†’ ä¸Šä¸‹ç¿»è½¬ï¼ˆè¿™é‡Œæ²¡ç”¨åˆ°ï¼‰
        f = [None, 3, None]  # flips (2-ud, 3-lr)
        # å­˜æ”¾é¢„æµ‹ç»“æžœ
        y = []  # outputs
        # éåŽ†æ¯ç§å¢žå¼ºæ–¹å¼
        for si, fi in zip(s, f):
            # è®­ç»ƒ/æŽ¨ç†æ—¶ â†’ ä¸€èˆ¬ç”¨æœ€å° strideï¼ˆä¿è¯å¤šå°ºåº¦ç‰¹å¾å¯¹é½ï¼‰
# å¢žå¼ºæŽ¨ç† _forward_augment æ—¶ â†’ è¿™é‡Œç”¨äº†æœ€å¤§ strideï¼Œç¡®ä¿ç¼©æ”¾åŽå›¾åƒå°ºå¯¸è‡³å°‘èƒ½æ•´é™¤æœ€ç²—ç³™çš„ç‰¹å¾å±‚
# fi = 3 â†’ å·¦å³ç¿»è½¬
# fi = None â†’ ä¸ç¿»è½¬
# å¯¹è¾“å…¥å›¾ç‰‡æŒ‰æ¯”ä¾‹ si ç¼©æ”¾
# scale_img gs æ˜¯æœ€å° strideï¼Œä¿è¯ç‰¹å¾å›¾å°ºå¯¸èƒ½è¢« stride æ•´é™¤
            xi = scale_img(x.flip(fi) if fi else x, si, gs=int(self.stride.max()))
            # ä¸€æ¬¡ forwardå¾—åˆ°é¢„æµ‹ç»“æžœ
            yi = self._forward_once(xi)[0]  # forward
            # cv2.imwrite(f'img_{si}.jpg', 255 * xi[0].cpu().numpy().transpose((1, 2, 0))[:, :, ::-1])  # save
            # å°†é¢„æµ‹æ¡†ä»Žå¢žå¼ºåŽçš„å›¾åƒåæ ‡æ˜ å°„å›žåŽŸå›¾åæ ‡
            yi = self._descale_pred(yi, fi, si, img_size)
            # åŠ å…¥åˆ—è¡¨
            y.append(yi)
        # è£å‰ªå¢žå¼ºæŽ¨ç†åŽçš„é¢„æµ‹ç»“æžœï¼ŒåŽ»æŽ‰è¾¹ç¼˜çš„â€œå¤šä½™é¢„æµ‹æ¡†â€ã€‚
# é¿å…å‡ºçŽ°åæ ‡è¶…å‡ºå›¾åƒçš„æƒ…å†µ
        y = self._clip_augmented(y)  # clip augmented tails
        # è¿™é‡Œ dim=1ï¼Œå³ åœ¨ç¬¬ 1 ä¸ªç»´åº¦ï¼ˆnum_predictionsï¼‰ä¸Šæ‹¼æŽ¥ä¸åŒå¢žå¼ºæ–¹å¼çš„ç»“æžœ
        return torch.cat(y, 1), None  # augmented inference, train

    # å°†æŽ¨ç†ç»“æžœæ¢å¤åˆ°åŽŸå›¾å°ºå¯¸
    def _descale_pred(self, p, flips, scale, img_size):
        # de-scale predictions following augmented inference (inverse operation)
        if self.inplace:
            # å¯¹ box çš„å‰å››ä¸ªå€¼ï¼ˆä¸­å¿ƒç‚¹åæ ‡å’Œå®½é«˜ï¼‰æŒ‰ç¼©æ”¾ç³»æ•° é™¤å›žåŽ»ã€‚
# å› ä¸ºé¢„æµ‹æ—¶è¾“å…¥å›¾åƒè¢«ç¼©æ”¾è¿‡ï¼Œæ‰€ä»¥è¿™é‡Œéœ€è¦æ¢å¤åˆ°åŽŸå§‹å¤§å°ã€‚
            p[..., :4] /= scale  # de-scale
            # æ³¨æ„è¿™é‡Œ img_size[0] æ˜¯è¾“å…¥å›¾åƒçš„é«˜åº¦ï¼Œimg_size[1] æ˜¯è¾“å…¥å›¾åƒçš„å®½åº¦ã€‚
            # ä¸Šä¸‹ç¿»è½¬æ¢å¤
            if flips == 2:
                p[..., 1] = img_size[0] - p[..., 1]  # de-flip ud
            # å·¦å³ç¿»è½¬æ¢å¤
            elif flips == 3:
                p[..., 0] = img_size[1] - p[..., 0]  # de-flip lr
        else:
            # éž inplace ç‰ˆæœ¬æ˜¯å•ç‹¬æ‹†æˆ x, y, wh å† cat å›žåŽ»ã€‚
            x, y, wh = p[..., 0:1] / scale, p[..., 1:2] / scale, p[..., 2:4] / scale  # de-scale
            if flips == 2:
                y = img_size[0] - y  # de-flip ud
            elif flips == 3:
                x = img_size[1] - x  # de-flip lr
            p = torch.cat((x, y, wh, p[..., 4:]), -1)
        return p

    # TTAçš„æ—¶å€™å¯¹åŽŸå›¾ç‰‡è¿›è¡Œè£å‰ª
    # YOLOv5 åœ¨ æµ‹è¯•å¢žå¼ºæŽ¨ç†ï¼ˆTTAï¼‰ åŽï¼Œå¯¹é¢„æµ‹ç»“æžœåšçš„ è£å‰ªæ“ä½œï¼Œç›®çš„æ˜¯åŽ»æŽ‰å¢žå¼ºæŽ¨ç†è¿‡ç¨‹ä¸­æŸäº›å¤šä½™æˆ–è¾¹ç¼˜çš„é¢„æµ‹æ¡†
    def _clip_augmented(self, y):
        # Clip YOLOv5 augmented inference tails
        # nl è¡¨ç¤ºæ£€æµ‹å¤´çš„å±‚æ•°ï¼Œä¸€èˆ¬æ˜¯ 3ï¼ˆP3, P4, P5ï¼‰
        nl = self.model[-1].nl  # number of detection layers (P3-P5)
        # æ¯å¾€ä¸Šä¸€ä¸ªå±‚çº§ï¼Œç½‘æ ¼ç‚¹æ•°é‡å¤§çº¦ ç¼©å° 4 å€ï¼ˆå› ä¸ºå®½é«˜å„å‡åŠ â†’ 2Ã—2=4ï¼‰
# æ‰€ä»¥ä½¿ç”¨ 4 ** x æ¥è¿‘ä¼¼æ¯å±‚ç›¸å¯¹ç½‘æ ¼ç‚¹æ•°é‡ï¼š
# æ³¨æ„è¿™é‡Œæ˜¯ç®€åŒ–çš„è¿‘ä¼¼ï¼Œä¸»è¦ç”¨äºŽæƒé‡åˆå§‹åŒ–æˆ–æ¨¡åž‹ç»Ÿè®¡ï¼Œä¸æ˜¯å®žé™…ç²¾ç¡®çš„æ ¼å­æ•°ã€‚
        g = sum(4 ** x for x in range(nl))  # grid points
        e = 1  # exclude layer count
        # y[0] æ˜¯å¢žå¼ºæŽ¨ç†å¾—åˆ°çš„é¢„æµ‹æ¡†å¼ é‡ï¼Œå½¢çŠ¶ [bs, num_preds, no]ã€‚
# shape[1] æ˜¯é¢„æµ‹æ¡†æ€»æ•° num_predsã€‚
        # y[0] æ˜¯å¢žå¼ºæŽ¨ç†åŽçš„ç¬¬ä¸€ä¸ªç»“æžœï¼ˆé€šå¸¸æ˜¯åŽŸå›¾æˆ–å¤§å°ºåº¦ç¼©æ”¾çš„è¾“å‡ºï¼‰ã€‚
# è®¡ç®—å‡ºè¦è£æŽ‰çš„ ç´¢å¼•æ•°é‡ iï¼Œç„¶åŽæŠŠæœ€åŽ i ä¸ªé¢„æµ‹æ¡†åŽ»æŽ‰ï¼ˆ:-iï¼‰ã€‚
# ä½œç”¨ï¼šåŽ»æŽ‰è¾¹ç¼˜é‡å¤æ¡†æˆ– TTA å¸¦æ¥çš„å°¾éƒ¨å†—ä½™é¢„æµ‹ã€‚
# y[0] â†’ å¢žå¼ºæŽ¨ç†åŽçš„ç¬¬ä¸€ä¸ªè¾“å‡ºï¼ˆé€šå¸¸æ˜¯åŽŸå›¾æˆ–å¤§å°ºåº¦ç¼©æ”¾è¾“å‡ºï¼‰
# y[0].shape[1] â†’ é¢„æµ‹æ¡†æ€»æ•°é‡
# (y[0].shape[1] // g) â†’ æ¯ä¸ªâ€œç½‘æ ¼ç‚¹æ¯”ä¾‹å•ä½â€å¯¹åº”çš„é¢„æµ‹æ¡†æ•°é‡
# sum(4 ** x for x in range(e)) â†’ è¦è£å‰ªçš„ç½‘æ ¼ç‚¹æ•°é‡
# i â†’ è®¡ç®—å‡ºè¦è£æŽ‰çš„é¢„æµ‹æ¡†æ•°é‡
# y[0][:, :-i] â†’ åŽ»æŽ‰æœ€åŽ i ä¸ªå†—ä½™æ¡†
        i = (y[0].shape[1] // g) * sum(4 ** x for x in range(e))  # indices
        y[0] = y[0][:, :-i]  # large
        # æŽ’é™¤/è£å‰ªå±‚æ•°ï¼Œé€šå¸¸æ˜¯ 1
# è¡¨ç¤ºåªè£å‰ªæœ€è¾¹ç¼˜çš„ä¸€å±‚ç½‘æ ¼é¢„æµ‹
        # nl-1 â†’ æœ€åŽä¸€å±‚ç´¢å¼•ï¼ˆå°å°ºåº¦å±‚ï¼Œé€šå¸¸ P5 â†’ index=2ï¼‰
# - x â†’ ç”¨äºŽå¾ªçŽ¯è£å‰ªæ›´å¤šå±‚ï¼ˆå¦‚æžœ e>1ï¼‰
# å®žé™…ä¸Š nl - 1 - x = æœ€å°å°ºåº¦å±‚çš„æŒ‡æ•°ï¼Œç”¨äºŽè®¡ç®—è¯¥å±‚ç½‘æ ¼ç‚¹çš„æ¯”ä¾‹
        i = (y[-1].shape[1] // g) * sum(4 ** (nl - 1 - x) for x in range(e))  # indices
        y[-1] = y[-1][:, i:]  # small
        return y

    '''åˆå§‹åŒ–åç½®biasesä¿¡æ¯,è®©ç½‘ç»œä¸€å¼€å§‹é¢„æµ‹æ¡†æ›´åˆç†ï¼ŒåŠ å¿«æ”¶æ•›'''
    def _initialize_biases(self, cf=None):  # initialize biases into Detect(), cf is class frequency
        # https://arxiv.org/abs/1708.02002 section 3.3
        # cf = torch.bincount(torch.tensor(np.concatenate(dataset.labels, 0)[:, 0]).long(), minlength=nc) + 1.
        # å–å‡ºæ¨¡åž‹çš„æœ€åŽä¸€å±‚ Detect å±‚ï¼Œä¹Ÿå°±æ˜¯é¢„æµ‹æ¡†è¾“å‡ºå±‚ã€‚
        m = self.model[-1]  # Detect() module
        # m.m æ˜¯ Detect å±‚çš„å¤šä¸ªè¾“å‡ºå·ç§¯å±‚ï¼ˆæ¯ä¸ªå°ºåº¦ä¸€ä¸ªï¼Œæ¯”å¦‚ P3, P4, P5ï¼‰ã€‚
# m.stride æ˜¯æ¯å±‚çš„æ­¥å¹…ï¼Œå¯¹åº”è¾“å‡ºæ ¼å­å¤§å°ã€‚
# å¾ªçŽ¯æ¯ä¸ªå°ºåº¦çš„å·ç§¯å±‚åšåç½®åˆå§‹åŒ–
        for mi, s in zip(m.m, m.stride):  # from
            # å°†å·ç§¯å±‚ bias å±•å¼€æˆ (na, no)ï¼Œ
# na = æ¯å±‚ anchor æ•°é‡
# no = æ¯ä¸ª anchor è¾“å‡ºæ•°é‡ = 5 + nc ï¼ˆx,y,w,h,obj + ç±»åˆ«æ¦‚çŽ‡ï¼‰
# ä¾‹å¦‚ nc=80, na=3 â†’ (3,85)
            b = mi.bias.view(m.na, -1)  # conv.bias(255) to (3,85)
            # 640 / s
# s â†’ ç‰¹å¾å›¾ stride
# 640 / s â†’ å½“å‰æ£€æµ‹å¤´ç‰¹å¾å›¾çš„å®½åº¦/é«˜åº¦ï¼ˆå‡è®¾è¾“å…¥å›¾ç‰‡ 640Ã—640ï¼‰
# (640 / s) ** 2 â†’ å½“å‰ç‰¹å¾å›¾çš„æ€»ç½‘æ ¼æ•°
# 8 / (640 / s) ** 2
# å‡è®¾ å¹³å‡æ¯å¼ å›¾ç‰‡æœ‰ 8 ä¸ªç›®æ ‡
# é™¤ä»¥æ€»ç½‘æ ¼æ•° â†’ å¾—åˆ° æ¯ä¸ªæ ¼å­å¹³å‡ç›®æ ‡æ¦‚çŽ‡
# math.log(...)
# YOLO ä½¿ç”¨ logits è¾“å‡º obj
# å› ä¸ºé¢„æµ‹æ¡†è¾“å‡ºç»è¿‡ sigmoid â†’ è½¬æ¢ä¸ºæ¦‚çŽ‡
# åˆå§‹åŒ– bias æ—¶ï¼Œè¦æŠŠæ¦‚çŽ‡è½¬æˆ logit
# è¿™é‡Œç”¨ log(8 / grid_count) è¿‘ä¼¼ logitï¼Œåˆå§‹åŒ– obj bias
# ç´¢å¼• 4 å¯¹åº” objectnessï¼ˆç›®æ ‡å­˜åœ¨æ¦‚çŽ‡ï¼‰ çš„åç½®
            b.data[:, 4] += math.log(8 / (640 / s) ** 2)  # obj (8 objects per 640 image)
            # b.data[:, 5:5 + m.nc] â†’ å½“å‰é¢„æµ‹æ¡† ç±»åˆ« biasï¼ˆm.nc = ç±»åˆ«æ•°ï¼‰
            # ä½†åœ¨æ•°å€¼è®¡ç®—ä¸­ï¼Œç”¨ 0.99999 æ›¿ä»£ 1ï¼Œå¯ä»¥ é˜²æ­¢æ•°å€¼ç¨³å®šæ€§é—®é¢˜é˜²æ­¢é™¤0
            # åˆå§‹åŒ– ç±»åˆ«åç½®ï¼Œæé«˜ä¸€å¼€å§‹å°æ¦‚çŽ‡ç±»è¢«é¢„æµ‹çš„æ¦‚çŽ‡ã€‚
# å¦‚æžœæ²¡æœ‰æä¾›ç±»åˆ«é¢‘çŽ‡ cfï¼š
# å‡è®¾æ¯ä¸ªç±»åˆ«æ¦‚çŽ‡å¹³å‡ 0.6 / nc
# å¦‚æžœæä¾›äº† cfï¼ˆæ¯ç±»æ ·æœ¬æ•°é‡ï¼‰ï¼š
# æ ¹æ® ç±»åˆ«é¢‘çŽ‡ æ¥åˆå§‹åŒ–åç½®ï¼Œä½¿å¸¸è§ç±»åˆ«åç½®é«˜ï¼Œç¨€æœ‰ç±»åˆ«åç½®ä½Ž
            b.data[:, 5:5 + m.nc] += math.log(0.6 / (m.nc - 0.99999)) if cf is None else torch.log(cf / cf.sum())  # cls
            # å°† bias å† reshape æˆå·ç§¯å±‚åŽŸæ¥çš„å½¢çŠ¶ (na * no,)
# è®¾ç½®ä¸ºå¯è®­ç»ƒå‚æ•°
            mi.bias = torch.nn.Parameter(b.view(-1), requires_grad=True)


Model = DetectionModel  # retain YOLOv5 'Model' class for backwards compatibility


class SegmentationModel(DetectionModel):
    # YOLOv5 segmentation model
    def __init__(self, cfg='yolov5s-seg.yaml', ch=3, nc=None, anchors=None):
        super().__init__(cfg, ch, nc, anchors)


class ClassificationModel(BaseModel):
    # YOLOv5 classification model
    def __init__(self, cfg=None, model=None, nc=1000, cutoff=10):  # yaml, model, number of classes, cutoff index
        super().__init__()
        self._from_detection_model(model, nc, cutoff) if model is not None else self._from_yaml(cfg)

    def _from_detection_model(self, model, nc=1000, cutoff=10):
        # Create a YOLOv5 classification model from a YOLOv5 detection model
        if isinstance(model, DetectMultiBackend):
            model = model.model  # unwrap DetectMultiBackend
        model.model = model.model[:cutoff]  # backbone
        m = model.model[-1]  # last layer
        ch = m.conv.in_channels if hasattr(m, 'conv') else m.cv1.conv.in_channels  # ch into module
        c = Classify(ch, nc)  # Classify()
        c.i, c.f, c.type = m.i, m.f, 'models.common.Classify'  # index, from, type
        model.model[-1] = c  # replace
        self.model = model.model
        self.stride = model.stride
        self.save = []
        self.nc = nc

    def _from_yaml(self, cfg):
        # Create a YOLOv5 classification model from a *.yaml file
        self.model = None

# d: å°±æ˜¯è¯»å–çš„ yolov5s.yaml è¿™ç§é…ç½®æ–‡ä»¶çš„ dictï¼ˆåŒ…å« anchors, nc, depth_multiple, width_multiple, backbone/head çš„ç»“æž„å®šä¹‰ï¼‰ã€‚
# chæ˜¯ä¸€ä¸ªç”¨æ¥ä¿å­˜ä¹‹å‰æ‰€æœ‰çš„æ¨¡å—è¾“å‡ºçš„channleã€‚
def parse_model(d, ch):  # model_dict, input_channels(3)
    '''===================1. èŽ·å–å¯¹åº”å‚æ•°============================'''
    # Parse a YOLOv5 model.yaml dictionary
    LOGGER.info(f"\n{'':>3}{'from':>18}{'n':>3}{'params':>10}  {'module':<40}{'arguments':<30}")
    # anchorsï¼šé”šæ¡†å®šä¹‰ï¼ˆæ¯å±‚æœ‰å¤šå°‘ä¸ª anchorï¼‰ã€‚
# ncï¼šç±»åˆ«æ•°ï¼ˆæ¯”å¦‚ COCO æ˜¯ 80ï¼‰ã€‚
# gdï¼šdepth_multipleï¼Œæ·±åº¦ç³»æ•°ï¼Œå†³å®šæ¯ä¸ªæ¨¡å—é‡å¤çš„æ¬¡æ•°ã€‚
# gwï¼šwidth_multipleï¼Œå®½åº¦ç³»æ•°ï¼Œå†³å®šå·ç§¯å±‚é€šé“æ•°çš„ç¼©æ”¾ã€‚
# actï¼šæ¿€æ´»å‡½æ•°ï¼Œå¯é€‰ï¼ˆæ¯”å¦‚ SiLUï¼‰ã€‚
    anchors, nc, gd, gw, act = d['anchors'], d['nc'], d['depth_multiple'], d['width_multiple'], d.get('activation')
    if act:
        # å¦‚æžœ yaml é‡Œå®šä¹‰äº†æ¿€æ´»å‡½æ•°ï¼Œå°±ä¿®æ”¹ Conv çš„é»˜è®¤æ¿€æ´»å‡½æ•°ã€‚
        # eval() æ˜¯ Python çš„å†…ç½®å‡½æ•°ï¼Œå®ƒä¼šæŠŠå­—ç¬¦ä¸²å½“ä½œ Python è¡¨è¾¾å¼æ‰§è¡Œã€‚
# act å¾ˆå¯èƒ½æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²ï¼Œæ¯”å¦‚ 'nn.SiLU()' æˆ– 'nn.ReLU()'ã€‚
# eval(act) ä¼šè¿”å›žå­—ç¬¦ä¸²è¡¨ç¤ºçš„ Python å¯¹è±¡
        Conv.default_act = eval(act)  # redefine default activation, i.e. Conv.default_act = nn.SiLU()
        LOGGER.info(f"{colorstr('activation:')} {act}")  # print
    # naï¼šæ¯å±‚çš„ anchor æ•°é‡ï¼ˆå¦‚æžœ anchors æ˜¯ listï¼Œå°±å–ç¬¬ä¸€ä¸ªå±‚çš„é•¿åº¦/2ï¼Œå› ä¸ºæ¯ä¸ª anchor ç”±å®½é«˜2ä¸ªå€¼ç»„æˆ
    na = (len(anchors[0]) // 2) if isinstance(anchors, list) else anchors  # number of anchors
    # noï¼šæ¯ä¸ªé¢„æµ‹å±‚çš„è¾“å‡ºç»´åº¦ = anchors Ã— (ç±»åˆ«æ•° + 5)ã€‚
# å…¶ä¸­ 5 = (x, y, w, h, obj_conf)
    no = na * (nc + 5)  # number of outputs = anchors * (classes + 5)

    '''===================2. æ­å»ºç½‘ç»œå‰å‡†å¤‡============================'''
    # éåŽ† backbone + headï¼Œæž„å»ºæ¯ä¸€å±‚æ¨¡å—ï¼Œå¹¶å¤„ç†å‚æ•°
    # layersï¼šä¿å­˜æ¯ä¸€å±‚æž„å»ºå¥½çš„ PyTorch æ¨¡å—ã€‚
# saveï¼šä¿å­˜éœ€è¦åœ¨ forward ä¸­ä¿ç•™è¾“å‡ºçš„å±‚ç´¢å¼•ï¼ˆå¦‚ skip connectionï¼‰ã€‚
# c2ï¼šå½“å‰å±‚è¾“å‡ºé€šé“æ•°ï¼Œåˆå§‹åŒ–ä¸ºè¾“å…¥é€šé“ ch[-1]ï¼ˆé€šå¸¸æ˜¯ 3ï¼ŒRGBï¼‰ã€‚
    layers, save, c2 = [], [], ch[-1]  # layers, savelist, ch out
    # éåŽ† backbone å’Œ head å®šä¹‰
    # fï¼šfrom â€”â€” è¾“å…¥æ¥è‡ªå“ªäº›å±‚ï¼ˆç´¢å¼•ï¼‰ã€‚
# nï¼šnumber â€”â€” æ¨¡å—é‡å¤æ¬¡æ•°ã€‚
# mï¼šmodule â€”â€” æ¨¡å—ç±»åž‹ï¼ˆå¦‚ Conv, Bottleneck, C3 ç­‰ï¼‰ã€‚
# argsï¼šæ¨¡å—å‚æ•°åˆ—è¡¨ï¼ˆå¦‚é€šé“æ•°ã€kernel_sizeã€stride ç­‰ï¼‰ã€‚
    for i, (f, n, m, args) in enumerate(d['backbone'] + d['head']):  # from, number, module, args
        # å¦‚æžœæ¨¡å—ç±»åž‹ m æ˜¯å­—ç¬¦ä¸²ï¼Œå°±ç”¨ eval è½¬æˆå®žé™… Python ç±»å¯¹è±¡ã€‚
# ä¾‹ï¼š"Conv" â†’ <class 'models.common.Conv'>ã€‚
# å¦‚æžœå·²ç»æ˜¯ç±»å¯¹è±¡ï¼Œå°±ç›´æŽ¥ä½¿ç”¨ã€‚
        m = eval(m) if isinstance(m, str) else m  # eval strings
        # éåŽ†æ¨¡å—å‚æ•° args
        for j, a in enumerate(args):
            # å¦‚æžœå‚æ•°æ˜¯å­—ç¬¦ä¸²ä¸”å¯ eval æˆ Python å¯¹è±¡ï¼Œå°± evalã€‚
# ä¾‹ï¼š"3*ch[0]" â†’ 9ï¼ˆå‡è®¾ ch[0]=3ï¼‰ã€‚
# ç”¨ contextlib.suppress(NameError) å¿½ç•¥ eval æ—¶å¯èƒ½äº§ç”Ÿçš„ NameErrorã€‚
# æœ‰äº›å­—ç¬¦ä¸²å¯èƒ½ä¾èµ–äºŽå¤–éƒ¨å˜é‡ï¼ˆå¦‚ chï¼‰ï¼Œå¦‚æžœå˜é‡ä¸å­˜åœ¨å°±è·³è¿‡ï¼Œä¸æŠ¥é”™ã€‚
# æœ€ç»ˆ args ä¸­æ¯ä¸ªå‚æ•°éƒ½è¢«è½¬æ¢ä¸ºå®žé™…æ•°å€¼æˆ–å¯¹è±¡ï¼Œå‡†å¤‡ä¼ ç»™æ¨¡å—æž„é€ å‡½æ•°ã€‚
            with contextlib.suppress(NameError):
                args[j] = eval(a) if isinstance(a, str) else a  # eval strings
        '''===================3. æ›´æ–°å½“å‰å±‚çš„å‚æ•°ï¼Œè®¡ç®—c2============================'''
        # nï¼šæ¨¡å—é‡å¤æ¬¡æ•°ï¼ˆæ·±åº¦ï¼‰ã€‚
# gd æ˜¯ depth_multipleï¼Œç”¨æ¥ç¼©æ”¾æ¨¡åž‹æ·±åº¦ï¼ˆä¾‹å¦‚ YOLOv5s â†’ YOLOv5m ä¼šåŠ æ·±ï¼‰ã€‚
# round(n * gd)ï¼šæ ¹æ®æ·±åº¦å€çŽ‡è°ƒæ•´é‡å¤æ¬¡æ•°ã€‚
# max(..., 1)ï¼šä¿è¯é‡å¤è‡³å°‘ä¸º 1 å±‚ã€‚
# n_ï¼šä¿å­˜åŽŸå§‹é‡å¤æ¬¡æ•°ï¼Œç”¨äºŽæ‰“å°æˆ–æ—¥å¿—ã€‚
        n = n_ = max(round(n * gd), 1) if n > 1 else n  # depth gain
        # åˆ¤æ–­å½“å‰æ¨¡å—æ˜¯å¦å±žäºŽ å·ç§¯/ç“¶é¢ˆç±»æ¨¡å—ï¼ˆå¯ä»¥ç¼©æ”¾é€šé“çš„å±‚ï¼‰ã€‚
# YOLOv5 ä¸­å¤§å¤šæ•° backbone/head æ¨¡å—éƒ½æ˜¯è¿™äº›ç±»åž‹ã€‚
        if m in {
                Conv, GhostConv, Bottleneck, GhostBottleneck, SPP, SPPF, DWConv, MixConv2d, Focus, CrossConv,
                BottleneckCSP, C3, C3TR, C3SPP, C3Ghost, nn.ConvTranspose2d, DWConvTranspose2d, C3x}:
            # è¾“å…¥é€šé“æ•°ï¼Œæ¥è‡ª ch[f]ã€‚
# f å¯ä»¥æ˜¯å•ä¸ªç´¢å¼•æˆ–åˆ—è¡¨ï¼ˆskip connectionï¼‰ã€‚
# c2ï¼šè¾“å‡ºé€šé“æ•°ï¼Œä¸€èˆ¬æ˜¯ args[0]ï¼ˆå³ yaml ä¸­å®šä¹‰çš„è¾“å‡ºé€šé“ï¼‰
            c1, c2 = ch[f], args[0]
            # c2 != noï¼šæŽ’é™¤æœ€åŽ Detect å±‚ï¼Œå› ä¸ºå®ƒçš„è¾“å‡ºé€šé“æ•°å·²ç»å›ºå®šï¼ˆno = na * (nc + 5)ï¼‰
            if c2 != no:  # if not output
                # make_divisible(..., 8)ï¼šä¿è¯é€šé“æ•°æ˜¯ 8 çš„å€æ•°ï¼ˆç¡¬ä»¶ä¼˜åŒ–è¦æ±‚ï¼Œå¦‚ GPU/CPU SIMD å¯¹é½ï¼‰ã€‚
# ä¾‹å¦‚ï¼ŒåŽŸæœ¬é€šé“ 32ï¼Œgw=1.25 â†’ 32*1.25=40 â†’ make_divisible(40,8) = 40ã€‚
                c2 = make_divisible(c2 * gw, 8)

            '''===================4.ä½¿ç”¨å½“å‰å±‚çš„å‚æ•°æ­å»ºå½“å‰å±‚============================'''
            # c1ï¼šè¾“å…¥é€šé“
# c2ï¼šè¾“å‡ºé€šé“
# *args[1:]ï¼šä¿ç•™åŽŸæœ¬å‰©ä½™å‚æ•°ï¼ˆkernelã€stride ç­‰ï¼‰
            args = [c1, c2, *args[1:]]
            # å¯¹ CSP/Bottleneck ç±»æ¨¡å—ï¼š
# éœ€è¦æŒ‡å®šé‡å¤æ¬¡æ•° nï¼Œæ’å…¥åˆ°å‚æ•°åˆ—è¡¨ç¬¬ 3 ä¸ªä½ç½®ï¼ˆç´¢å¼• 2ï¼‰ã€‚
# ç„¶åŽå°† n=1ï¼Œå› ä¸ºåŽç»­ä¼šç›´æŽ¥ç”¨ nn.Sequential(*[m(*args) for _ in range(n)]) æ¥é‡å¤æ¨¡å—
            if m in {BottleneckCSP, C3, C3TR, C3Ghost, C3x}:
                args.insert(2, n)  # number of repeats
                n = 1
        # å¯¹äºŽæ‰¹é‡å½’ä¸€åŒ–åªéœ€è¦è¾“å…¥é€šé“æ•° ch[f]ï¼Œå…¶ä»–å‚æ•°éƒ½ç”¨é»˜è®¤å€¼
        elif m is nn.BatchNorm2d:
            args = [ch[f]]
        # Concatï¼ˆæ‹¼æŽ¥æ¨¡å—ï¼‰ï¼š
# è¾“å‡ºé€šé“ = è¾“å…¥å„å±‚é€šé“ä¹‹å’Œã€‚
        elif m is Concat:
            c2 = sum(ch[x] for x in f)
        # TODO: channel, gw, gd
        # Detect/Segment å±‚ï¼ˆé¢„æµ‹å±‚ï¼‰
        elif m in {Detect, Segment}:
            # æ·»åŠ æ¯å±‚è¾“å…¥é€šé“åˆ—è¡¨ [ch[x] for x in f]
            args.append([ch[x] for x in f])
            # args[1] å°±æ˜¯ Detect/Segment æ¨¡å—åœ¨æž„é€ å‡½æ•°é‡Œçš„ç¬¬äºŒä¸ªå‚æ•°â€”â€”é”šç‚¹ä¿¡æ¯ï¼Œæ‰€ä»¥é€šå¸¸ç”¨æ¥è¡¨ç¤ºé”šæ¡†æ•°é‡ã€‚
            # å¦‚é…ç½®æ–‡ä»¶ä¸­   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)
            if isinstance(args[1], int):  # number of anchors
                # å¦‚æžœæ˜¯æ•´æ•°ï¼Œæ¯”å¦‚ 3ï¼Œè¯´æ˜Žæ¯ä¸ªè¾“å‡ºé€šé“æœ‰ 3 ä¸ª anchorã€‚
# [list(range(args[1] * 2))] * len(f)ï¼š
# args[1]*2 æ˜¯å› ä¸ºæ¯ä¸ª anchor æœ‰ (x, y) ä¸¤ä¸ªåæ ‡ï¼Œæ‰€ä»¥ä¹˜ 2ã€‚
# list(range(...)) ç”Ÿæˆç´¢å¼•åˆ—è¡¨ [0, 1, 2, 3, 4, 5]ã€‚
# * len(f) è¡¨ç¤ºä¸ºæ¯ä¸ªè¾“å…¥ç´¢å¼•å¤åˆ¶ä¸€ä»½ã€‚
# ç›®çš„æ˜¯æŠŠæ•´æ•°å½¢å¼çš„é”šæ¡†æ•°è½¬æ¢æˆåˆ—è¡¨å½¢å¼ï¼Œæ–¹ä¾¿ Detect/Segment æ¨¡å—ä½¿ç”¨
# f æ˜¯ ä»Žå“ªäº›å±‚è¾“å‡ºç‰¹å¾å›¾ï¼ˆé€šå¸¸ P3-P5 â†’ 3 å±‚ï¼‰
                args[1] = [list(range(args[1] * 2))] * len(f)
            if m is Segment:
                # å¦‚æžœæ¨¡å—æ˜¯ Segmentï¼ˆåˆ†å‰²å¤´ï¼‰ï¼Œå¯¹ args[3] åšè°ƒæ•´ã€‚
# args[3] é€šå¸¸æ˜¯è¾“å‡ºé€šé“æ•°æˆ–è€…æŸä¸ªå·ç§¯å±‚çš„é€šé“æ•°ã€‚
# gw æ˜¯å®½åº¦å¢žç›Šï¼ˆwidth multiplierï¼‰ï¼Œç”¨äºŽè°ƒæ•´æ¨¡åž‹å¤§å°ã€‚
# make_divisible(..., 8) ä¼šå°†é€šé“æ•°å‘ä¸Šå‡‘æ•´ä¸º 8 çš„å€æ•°ï¼Œä¿è¯å·ç§¯æ ¸å¯¹é½ç¡¬ä»¶ï¼ˆå°¤å…¶æ˜¯ GPUï¼‰æ•ˆçŽ‡ã€‚
                args[3] = make_divisible(args[3] * gw, 8)
        # Contract æ˜¯â€œæ”¶ç¼©â€æ¨¡å—ï¼Œå°†ç©ºé—´åˆ†è¾¨çŽ‡ä¸‹é‡‡æ ·ï¼Œåˆ†è¾¨çŽ‡å‡å°ï¼Œä½†é€šé“æ•°å¢žåŠ ã€‚
        # ä¾‹å¦‚è¾“å…¥é€šé“ c=64ï¼Œargs[0]=2ï¼ˆç¼©å° 2 å€ï¼‰ï¼Œåˆ™ c2 = 64 * 2^2 = 256
        elif m is Contract:
            c2 = ch[f] * args[0] ** 2
        # Expand æ˜¯â€œæ‰©å±•â€æ¨¡å—ï¼Œå°†ç©ºé—´åˆ†è¾¨çŽ‡ä¸Šé‡‡æ ·ï¼Œåˆ†è¾¨çŽ‡å¢žåŠ ï¼Œä½†é€šé“æ•°å‡å°‘
        elif m is Expand:
            # ä¾‹å¦‚è¾“å…¥é€šé“ c=256ï¼Œargs[0]=2ï¼ˆæ”¾å¤§ 2 å€ï¼‰ï¼Œåˆ™ c2 = 256 // 4 = 64
            c2 = ch[f] // args[0] ** 2
        else:
            c2 = ch[f]
        '''===================5.æ‰“å°å’Œä¿å­˜layersä¿¡æ¯============================'''
        # parse_model çš„æœ€åŽå…³é”®æ­¥éª¤ï¼Œå®Œæˆäº† æ¨¡å—å®žä¾‹åŒ–ã€å±žæ€§ç»‘å®šã€æ—¥å¿—è¾“å‡ºã€forward ä¿å­˜å±‚ç´¢å¼•ä»¥åŠè¾“å‡ºé€šé“æ›´æ–°
        # *argsä¼ ç»™æ¨¡å—çš„å‚æ•°ï¼Œæ¯”å¦‚ [512, 1, 1] â†’ è¾“å‡ºé€šé“=512, å·ç§¯æ ¸=1, æ­¥å¹…=1ã€‚
        # m(*args)å®žä¾‹åŒ–ä¸€ä¸ªæ¨¡å—å¯¹è±¡ï¼Œæ¯”å¦‚ Conv(512, 1, 1)ã€‚
        # for _ in range(n)ç”Ÿæˆ n ä¸ªç›¸åŒçš„æ¨¡å—å¯¹è±¡ã€‚
        # *(...)æŠŠç”Ÿæˆçš„æ¨¡å—å¯¹è±¡è§£åŒ…æˆä½ç½®å‚æ•°ã€‚å®ƒè¦çš„æ˜¯å¤šä¸ªç‹¬ç«‹å‚æ•°ï¼Œè€Œä¸æ˜¯ä¸€ä¸ªç”Ÿæˆå™¨æˆ–åˆ—è¡¨ã€‚*å°†åˆ—è¡¨è§£åŒ…æˆä¸€ä¸ªä¸ªå‚æ•°
        # nn.Sequential(...)æŠŠè¿™ n ä¸ªæ¨¡å—é¡ºåºå †å ï¼Œä½œä¸ºä¸€ä¸ªæ•´ä½“æ¨¡å—ã€‚
        m_ = nn.Sequential(*(m(*args) for _ in range(n))) if n > 1 else m(*args)  # module
        # èŽ·å–æ¨¡å—ç±»åž‹åç§°ï¼Œç”¨äºŽæ‰“å°æ—¥å¿—
        # '__main__.C3(64,64,3)'[8:-2] -> 'C3(64,64,3'
        t = str(m)[8:-2].replace('__main__.', '')  # module type
        # è®¡ç®—è¯¥æ¨¡å—çš„å‚æ•°æ€»æ•°ï¼ˆweights + biasï¼‰ã€‚
# x.numel() è¿”å›žæ¯ä¸ª tensor çš„å…ƒç´ æ•°é‡ï¼Œç´¯åŠ å¾—åˆ°æ€»å‚æ•°é‡ã€‚
        np = sum(x.numel() for x in m_.parameters())  # number params
        # åŠ¨æ€ç»‘å®šå±žæ€§åˆ°æ¨¡å—å¯¹è±¡ï¼š
# iï¼šå±‚ç´¢å¼•
# fï¼šè¯¥å±‚è¾“å…¥æ¥è‡ªå“ªäº›å±‚
# typeï¼šæ¨¡å—ç±»åž‹åç§°
# npï¼šå‚æ•°æ€»æ•°
# æ–¹ä¾¿åŽç»­ debug æˆ– forward trace
        m_.i, m_.f, m_.type, m_.np = i, f, t, np  # attach index, 'from' index, type, number params
        # æ‰“å°æ—¥å¿—ï¼Œæ˜¾ç¤ºè¯¥å±‚ä¿¡æ¯ï¼š
# iï¼šå±‚ç´¢å¼•
# fï¼šfrom
# n_ï¼šé‡å¤æ¬¡æ•°
# npï¼šå‚æ•°æ•°é‡
# tï¼šæ¨¡å—ç±»åž‹
# argsï¼šæ¨¡å—å‚æ•°åˆ—è¡¨
        LOGGER.info(f'{i:>3}{str(f):>18}{n_:>3}{np:10.0f}  {t:<40}{str(args):<30}')  # print
        # if x != -1
# è·³è¿‡ -1ï¼Œå› ä¸º -1 è¡¨ç¤ºâ€œä¸Šä¸€å±‚è¾“å‡ºâ€ï¼Œå®ƒå¿…ç„¶å·²ç»åœ¨è®¡ç®—ä¸­ï¼Œä¸éœ€è¦ä¸“é—¨ä¿å­˜ã€‚
# x % i å…¶å®žæ˜¯ä¸ºäº†æŠŠè´Ÿç´¢å¼•ï¼ˆå€’æ•°ç¬¬å‡ å±‚ï¼‰è½¬æˆæ­£ç´¢å¼•
# å¦‚x = -2   â†’  -2 % 7 = 5   # å€’æ•°ç¬¬2å±‚å°±æ˜¯æ­£å‘ç´¢å¼•5
# x = 6    â†’   6 % 7 = 6   # æ­£å¸¸ç´¢å¼•ä¿æŒä¸å˜
        save.extend(x % i for x in ([f] if isinstance(f, int) else f) if x != -1)  # append to savelist
        # å°†å®žä¾‹åŒ–çš„æ¨¡å—åŠ å…¥ layers åˆ—è¡¨ï¼Œæœ€ç»ˆæž„å»ºç½‘ç»œã€‚
        layers.append(m_)
        # æ›´æ–°é€šé“åˆ—è¡¨ chï¼š
# ch[i] è¡¨ç¤ºç¬¬ i å±‚è¾“å‡ºé€šé“æ•°ï¼Œç”¨äºŽåŽç»­å±‚è®¡ç®—ã€‚
# ç¬¬ 0 å±‚ç‰¹æ®Šå¤„ç†ï¼Œå…ˆæ¸…ç©ºåˆ—è¡¨
        if i == 0:
            ch = []
        ch.append(c2)
    # nn.Sequential(*layers)ï¼šå®Œæ•´çš„ YOLOv5 ç½‘ç»œã€‚
# sorted(save)ï¼šforward æ—¶éœ€è¦ç¼“å­˜çš„å±‚ç´¢å¼•åˆ—è¡¨
    return nn.Sequential(*layers), sorted(save)


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument('--cfg', type=str, default='yolov5s.yaml', help='model.yaml')
    parser.add_argument('--batch-size', type=int, default=1, help='total batch size for all GPUs')
    parser.add_argument('--device', default='', help='cuda device, i.e. 0 or 0,1,2,3 or cpu')
    parser.add_argument('--profile', action='store_true', help='profile model speed')
    parser.add_argument('--line-profile', action='store_true', help='profile model speed layer by layer')
    parser.add_argument('--test', action='store_true', help='test all yolo*.yaml')
    opt = parser.parse_args()
    opt.cfg = check_yaml(opt.cfg)  # check YAML
    print_args(vars(opt))
    device = select_device(opt.device)

    # Create model
    # æ ¹æ®é…ç½®æ–‡ä»¶ opt.cfgï¼ˆYOLO çš„ yaml æ–‡ä»¶ï¼Œå®šä¹‰äº†ç½‘ç»œç»“æž„ï¼‰å®žä¾‹åŒ–ä¸€ä¸ª Modelã€‚
# .to(device) æŠŠæ•´ä¸ªæ¨¡åž‹æ¬åˆ° GPU æˆ– CPUï¼Œç¡®ä¿å’Œè¾“å…¥ im åœ¨åŒä¸€è®¾å¤‡ä¸Š
    im = torch.rand(opt.batch_size, 3, 640, 640).to(device)
    model = Model(opt.cfg).to(device)

    # Options
    if opt.line_profile:  # profile layer by layer
        # é€å±‚åˆ†æžæ€§èƒ½ã€‚
# è¿™é‡Œè°ƒç”¨ model(im, profile=True)ï¼Œä¼šè§¦å‘ä½ ä¹‹å‰çœ‹åˆ°çš„ _forward_once é‡Œå¯¹ profile çš„å¤„ç†ï¼š
# æ¯å±‚é€šè¿‡ thop.profile è®¡ç®— FLOPsï¼ˆè¿ç®—é‡ï¼‰ã€‚
# è®¡æ—¶è¿è¡Œ 10 æ¬¡ç®—å¹³å‡è€—æ—¶ã€‚
# æœ€åŽæ‰“å°æ¯ä¸€å±‚çš„è€—æ—¶ã€GFLOPsã€å‚æ•°æ•°é‡ã€‚
# ç”¨äºŽé€å±‚æ€§èƒ½è¯Šæ–­ï¼ˆç“¶é¢ˆåœ¨å“ªä¸€å±‚ï¼‰ã€‚
        model(im, profile=True)

    elif opt.profile:  # profile forward-backward
#         æ•´ä½“æ­£å‘ + åå‘ä¼ æ’­ profilingã€‚
# profile(...) æ˜¯ utils é‡Œçš„ä¸€ä¸ªå·¥å…·å‡½æ•°ï¼ŒåŠŸèƒ½ç±»ä¼¼äºŽ torch.utils.benchmarkï¼š
# è¿™é‡Œå¯¹æ•´ä¸ª modelï¼ˆopï¼‰åš 3 æ¬¡è¿è¡Œï¼Œç»Ÿè®¡å¹³å‡è€—æ—¶ã€æ˜¾å­˜å ç”¨ç­‰æŒ‡æ ‡ã€‚
# å’Œé€å±‚ä¸åŒï¼Œè¿™é‡Œæ˜¯ç«¯åˆ°ç«¯æµ‹è¯•ï¼ŒåŒ…æ‹¬ forward + backwardã€‚
# å¸¸ç”¨äºŽè®­ç»ƒå‰è¯„ä¼°ï¼šè¿™ä¸ªæ¨¡åž‹åœ¨å½“å‰ç¡¬ä»¶ä¸Šè·‘ä¸€æ¬¡å¤§æ¦‚éœ€è¦å¤šå°‘æ˜¾å­˜ã€è€—æ—¶
        results = profile(input=im, ops=[model], n=3)

    elif opt.test:  # test all models
        # éåŽ†é¡¹ç›®ä¸­æ‰€æœ‰ yolo*.yaml é…ç½®æ–‡ä»¶ï¼ˆä¾‹å¦‚ yolov5s.yaml, yolov5m.yaml ...ï¼‰ã€‚
# å°è¯•å®žä¾‹åŒ– Model(cfg)ã€‚
# å¦‚æžœæŸä¸ªé…ç½®å‡ºé”™ï¼ˆç»“æž„å®šä¹‰é”™è¯¯/ä¸å…¼å®¹ï¼‰ï¼Œå°±æ•èŽ·å¼‚å¸¸å¹¶æ‰“å°å‡ºæ¥ã€‚
# ä½œç”¨ï¼šå¿«é€ŸéªŒè¯é¡¹ç›®é‡Œæ‰€æœ‰æ¨¡åž‹é…ç½®æ–‡ä»¶èƒ½å¦æˆåŠŸåŠ è½½ï¼Œä¸ä¼šå½±å“ä¸»æµç¨‹ã€‚
# .rglob(pattern) æ˜¯ é€’å½’æœç´¢ æ–¹æ³•ï¼Œä¼šä»Žå½“å‰ç›®å½•å¼€å§‹ï¼ŒæŸ¥æ‰¾ æ‰€æœ‰å­ç›®å½•ï¼ŒåŒ¹é…æ–‡ä»¶åæ¨¡å¼çš„æ–‡ä»¶
        for cfg in Path(ROOT / 'models').rglob('yolo*.yaml'):
            try:
                _ = Model(cfg)
            except Exception as e:
                print(f'Error in {cfg}: {e}')

    else:  # report fused model summary
        model.fuse()
